{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINVENT4 LibInvent - NVIDIA DGX Spark (Baseline)\n",
    "## DENV NS2B-NS3 Protease Inhibitor Generation\n",
    "\n",
    "**Hardware**: NVIDIA DGX Spark (128GB unified memory, GB10 GPU, 20 CPU cores)\n",
    "\n",
    "**实验设计**: Baseline - 建立稳定参考线\n",
    "\n",
    "| 参数 | 值 | 理由 |\n",
    "|------|-----|------|\n",
    "| batch_size | 128 | 减少CPU瓶颈，提高GPU利用率 |\n",
    "| sigma | 140 | 平衡探索与收敛 |\n",
    "| rate | 0.0001 | 稳定学习 |\n",
    "| bucket_size | 20 | 适度多样性压力 |\n",
    "\n",
    "---\n",
    "\n",
    "### TensorBoard 实时监控\n",
    "```bash\n",
    "# 在另一个终端运行：\n",
    "tensorboard --logdir experiments/runs/baseline_run1/tensorboard --bind_all --port 6006\n",
    "```\n",
    "然后访问 http://<spark-ip>:6006\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: 环境检查和导入\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import threading\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"REINVENT4 LibInvent - DGX Spark Baseline\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Python版本: {sys.version.split()[0]}\")\n",
    "print(f\"工作目录: {os.getcwd()}\")\n",
    "\n",
    "# 检查CUDA\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\nPyTorch版本: {torch.__version__}\")\n",
    "    print(f\"CUDA可用: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA版本: {torch.version.cuda}\")\n",
    "        print(f\"GPU设备: {torch.cuda.get_device_name(0)}\")\n",
    "        total_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        free_mem = (torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)) / 1e9\n",
    "        print(f\"GPU内存: {total_mem:.1f} GB total, ~{free_mem:.1f} GB free\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n⚠️ PyTorch检查失败: {e}\")\n",
    "\n",
    "# 检查CPU\n",
    "cpu_count = os.cpu_count()\n",
    "print(f\"\\nCPU核心数: {cpu_count}\")\n",
    "\n",
    "print(\"\\n✅ 环境检查完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: 路径配置\n",
    "REINVENT_HOME = Path.home() / \"aidd\" / \"DENV_Drug_Discovery\"\n",
    "EXP_NAME = \"baseline_run1\"\n",
    "EXP_DIR = REINVENT_HOME / \"experiments\" / \"runs\" / EXP_NAME\n",
    "\n",
    "print(\"路径配置:\")\n",
    "print(f\"  REINVENT根目录: {REINVENT_HOME}\")\n",
    "print(f\"  实验目录: {EXP_DIR}\")\n",
    "\n",
    "# 创建实验目录\n",
    "EXP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(EXP_DIR / \"tensorboard\").mkdir(exist_ok=True)\n",
    "print(f\"\\n✅ 实验目录已创建: {EXP_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: 文件完整性检查\n",
    "print(\"检查必需文件...\\n\")\n",
    "\n",
    "required_files = {\n",
    "    \"Prior模型\": REINVENT_HOME / \"priors\" / \"libinvent.prior\",\n",
    "    \"Agent模型\": REINVENT_HOME / \"priors\" / \"denv_libinvent_model_v2.model\",\n",
    "    \"Scaffold文件\": REINVENT_HOME / \"data\" / \"pyrrolidine_dual_aryl.smi\",\n",
    "    \"QSAR模型\": REINVENT_HOME / \"models\" / \"random_forest_champion.joblib\",\n",
    "    \"QSAR插件\": REINVENT_HOME / \"reinvent_plugins\" / \"components\" / \"comp_qsar_scorer.py\",\n",
    "}\n",
    "\n",
    "all_exists = True\n",
    "for name, path in required_files.items():\n",
    "    exists = path.exists()\n",
    "    status = \"✅\" if exists else \"❌\"\n",
    "    print(f\"{status} {name}: {path}\")\n",
    "    if not exists:\n",
    "        all_exists = False\n",
    "\n",
    "if all_exists:\n",
    "    print(\"\\n✅ 所有必需文件检查通过\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"缺少必需文件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Scaffold诊断 - 关键！\n",
    "print(\"=\" * 80)\n",
    "print(\"Scaffold诊断\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "scaffold_file = REINVENT_HOME / \"data\" / \"pyrrolidine_dual_aryl.smi\"\n",
    "with open(scaffold_file) as f:\n",
    "    scaffolds = [line.strip().split()[0] for line in f if line.strip() and not line.startswith('#')]\n",
    "\n",
    "print(f\"\\n共 {len(scaffolds)} 个scaffolds:\\n\")\n",
    "\n",
    "valid_count = 0\n",
    "attachment_stats = {}\n",
    "\n",
    "for i, smi in enumerate(scaffolds):\n",
    "    # 统计attachment points\n",
    "    n_attach = smi.count('[*]')\n",
    "    attachment_stats[n_attach] = attachment_stats.get(n_attach, 0) + 1\n",
    "    \n",
    "    # 验证SMILES\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol:\n",
    "        valid_count += 1\n",
    "        status = \"✓\"\n",
    "    else:\n",
    "        status = \"✗ INVALID\"\n",
    "    \n",
    "    # 截断显示\n",
    "    display_smi = smi[:55] + \"...\" if len(smi) > 55 else smi\n",
    "    print(f\"  {i+1:2d}. [{n_attach}个连接点] {status} {display_smi}\")\n",
    "\n",
    "print(f\"\\n统计:\")\n",
    "print(f\"  有效scaffolds: {valid_count}/{len(scaffolds)}\")\n",
    "print(f\"  连接点分布: {attachment_stats}\")\n",
    "\n",
    "if valid_count < len(scaffolds):\n",
    "    print(\"\\n⚠️ 警告: 存在无效scaffold，可能导致高invalid率！\")\n",
    "else:\n",
    "    print(\"\\n✅ 所有scaffolds有效\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: 生成优化配置文件 (Baseline)\n",
    "print(\"=\" * 80)\n",
    "print(\"生成Baseline配置\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================\n",
    "# 核心参数 - Baseline配置\n",
    "# ============================================\n",
    "BATCH_SIZE = 128        # ↓ 从512降至128，减少CPU瓶颈\n",
    "SIGMA = 140             # 平衡探索与收敛\n",
    "LEARNING_RATE = 0.0001  # 稳定学习率\n",
    "BUCKET_SIZE = 20        # 适度多样性\n",
    "MIN_SCORE = 0.4         # ↓ 从0.6降至0.4，初期允许探索\n",
    "MIN_STEPS = 1500        # 最小步数\n",
    "MAX_STEPS = 4000        # 最大步数 (128×4000=512K分子)\n",
    "MEMORY_SIZE = 50        # ↓ 从100降至50\n",
    "SAMPLE_SIZE = 10        # ↓ 从20降至10\n",
    "\n",
    "config_content = f'''# REINVENT4 LibInvent - Baseline Configuration\n",
    "# Generated at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "# \n",
    "# 参数理论依据:\n",
    "#   batch_size=128: 减少CPU SMILES处理瓶颈，提高GPU利用率\n",
    "#   sigma=140: DAP公式 augmented_nlls = agent_nlls + sigma*(1-scores)\n",
    "#              更高sigma增强探索，防止早熟收敛\n",
    "#   rate=0.0001: 与较小batch配合，保持稳定的有效学习率\n",
    "#   bucket_size=20: 每个Murcko scaffold允许20个变体后才惩罚\n",
    "\n",
    "run_type = \"staged_learning\"\n",
    "device = \"cuda:0\"\n",
    "tb_logdir = \"experiments/runs/{EXP_NAME}/tensorboard\"\n",
    "json_out_config = \"experiments/runs/{EXP_NAME}/_config.json\"\n",
    "\n",
    "[parameters]\n",
    "summary_csv_prefix = \"experiments/runs/{EXP_NAME}/results\"\n",
    "use_checkpoint = true\n",
    "purge_memories = false\n",
    "\n",
    "prior_file = \"priors/libinvent.prior\"\n",
    "agent_file = \"priors/denv_libinvent_model_v2.model\"\n",
    "smiles_file = \"data/pyrrolidine_dual_aryl.smi\"\n",
    "\n",
    "# ============================================\n",
    "# 优化参数 - 针对DGX Spark\n",
    "# ============================================\n",
    "batch_size = {BATCH_SIZE}\n",
    "unique_sequences = true\n",
    "randomize_smiles = false\n",
    "\n",
    "[learning_strategy]\n",
    "type = \"dap\"\n",
    "sigma = {SIGMA}\n",
    "rate = {LEARNING_RATE}\n",
    "\n",
    "[diversity_filter]\n",
    "type = \"IdenticalMurckoScaffold\"\n",
    "bucket_size = {BUCKET_SIZE}\n",
    "minscore = {MIN_SCORE}\n",
    "\n",
    "[inception]\n",
    "smiles_file = \"data/pyrrolidine_dual_aryl.smi\"\n",
    "memory_size = {MEMORY_SIZE}\n",
    "sample_size = {SAMPLE_SIZE}\n",
    "\n",
    "# ============================================\n",
    "# Stage 1: 主训练阶段\n",
    "# ============================================\n",
    "[[stage]]\n",
    "max_score = 0.85\n",
    "min_steps = {MIN_STEPS}\n",
    "max_steps = {MAX_STEPS}\n",
    "chkpt_file = \"experiments/runs/{EXP_NAME}/checkpoint.chkpt\"\n",
    "\n",
    "[stage.scoring]\n",
    "type = \"arithmetic_mean\"\n",
    "\n",
    "# ========================================\n",
    "# 第一优先级：QSAR活性预测 (权重3.0)\n",
    "# ========================================\n",
    "[[stage.scoring.component]]\n",
    "[stage.scoring.component.QSARScorer]\n",
    "[[stage.scoring.component.QSARScorer.endpoint]]\n",
    "name = \"DENV_Activity\"\n",
    "weight = 3.0\n",
    "\n",
    "[stage.scoring.component.QSARScorer.endpoint.params]\n",
    "model_path = \"models/random_forest_champion.joblib\"\n",
    "\n",
    "[stage.scoring.component.QSARScorer.endpoint.transform]\n",
    "type = \"double_sigmoid\"\n",
    "low = 4.5\n",
    "high = 9.0\n",
    "coef_div = 9.0\n",
    "coef_si = 8.0\n",
    "coef_se = 8.0\n",
    "\n",
    "# ========================================\n",
    "# 第二优先级：化学稳定性\n",
    "# ========================================\n",
    "[[stage.scoring.component]]\n",
    "[stage.scoring.component.NumAtomStereoCenters]\n",
    "[[stage.scoring.component.NumAtomStereoCenters.endpoint]]\n",
    "name = \"Stereo_Centers\"\n",
    "weight = 0.6\n",
    "\n",
    "[stage.scoring.component.NumAtomStereoCenters.endpoint.transform]\n",
    "type = \"reverse_sigmoid\"\n",
    "low = 0\n",
    "high = 3\n",
    "k = 1.0\n",
    "\n",
    "[[stage.scoring.component]]\n",
    "[stage.scoring.component.CustomAlerts]\n",
    "[[stage.scoring.component.CustomAlerts.endpoint]]\n",
    "name = \"Stability_Alerts\"\n",
    "weight = 1.2\n",
    "\n",
    "[stage.scoring.component.CustomAlerts.endpoint.params]\n",
    "smarts = [\n",
    "    \"[*;r8]\", \"[*;r9]\", \"[*;r10]\",\n",
    "    \"[#8][#8]\",\n",
    "    \"[#6;+]\",\n",
    "    \"C#C\",\n",
    "    \"[NX3][NX3]\",\n",
    "    \"[SH]\",\n",
    "    \"[N+](=O)[O-]\",\n",
    "    \"S(=O)(=O)Cl\",\n",
    "    \"[F,Cl,Br,I][C,c][F,Cl,Br,I]\",\n",
    "]\n",
    "\n",
    "# ========================================\n",
    "# 第三优先级：类药性\n",
    "# ========================================\n",
    "[[stage.scoring.component]]\n",
    "[stage.scoring.component.Qed]\n",
    "[[stage.scoring.component.Qed.endpoint]]\n",
    "name = \"QED\"\n",
    "weight = 0.4\n",
    "\n",
    "[[stage.scoring.component]]\n",
    "[stage.scoring.component.SAScore]\n",
    "[[stage.scoring.component.SAScore.endpoint]]\n",
    "name = \"SA\"\n",
    "weight = 0.5\n",
    "\n",
    "[stage.scoring.component.SAScore.endpoint.transform]\n",
    "type = \"reverse_sigmoid\"\n",
    "low = 1.0\n",
    "high = 5.5\n",
    "k = 0.8\n",
    "\n",
    "# ========================================\n",
    "# 第四优先级：物理化学性质\n",
    "# ========================================\n",
    "[[stage.scoring.component]]\n",
    "[stage.scoring.component.MolecularWeight]\n",
    "[[stage.scoring.component.MolecularWeight.endpoint]]\n",
    "name = \"MW\"\n",
    "weight = 0.5\n",
    "\n",
    "[stage.scoring.component.MolecularWeight.endpoint.transform]\n",
    "type = \"double_sigmoid\"\n",
    "low = 280.0\n",
    "high = 550.0\n",
    "coef_div = 550.0\n",
    "coef_si = 15.0\n",
    "coef_se = 15.0\n",
    "\n",
    "[[stage.scoring.component]]\n",
    "[stage.scoring.component.SlogP]\n",
    "[[stage.scoring.component.SlogP.endpoint]]\n",
    "name = \"LogP\"\n",
    "weight = 0.4\n",
    "\n",
    "[stage.scoring.component.SlogP.endpoint.transform]\n",
    "type = \"double_sigmoid\"\n",
    "low = 1.0\n",
    "high = 4.5\n",
    "coef_div = 4.5\n",
    "coef_si = 10.0\n",
    "coef_se = 10.0\n",
    "\n",
    "[[stage.scoring.component]]\n",
    "[stage.scoring.component.TPSA]\n",
    "[[stage.scoring.component.TPSA.endpoint]]\n",
    "name = \"TPSA\"\n",
    "weight = 0.3\n",
    "\n",
    "[stage.scoring.component.TPSA.endpoint.transform]\n",
    "type = \"double_sigmoid\"\n",
    "low = 40.0\n",
    "high = 120.0\n",
    "coef_div = 120.0\n",
    "coef_si = 15.0\n",
    "coef_se = 15.0\n",
    "\n",
    "[[stage.scoring.component]]\n",
    "[stage.scoring.component.HBondAcceptors]\n",
    "[[stage.scoring.component.HBondAcceptors.endpoint]]\n",
    "name = \"HBA\"\n",
    "weight = 0.3\n",
    "\n",
    "[stage.scoring.component.HBondAcceptors.endpoint.transform]\n",
    "type = \"reverse_sigmoid\"\n",
    "low = 2\n",
    "high = 8\n",
    "k = 0.5\n",
    "\n",
    "[[stage.scoring.component]]\n",
    "[stage.scoring.component.HBondDonors]\n",
    "[[stage.scoring.component.HBondDonors.endpoint]]\n",
    "name = \"HBD\"\n",
    "weight = 0.2\n",
    "\n",
    "[stage.scoring.component.HBondDonors.endpoint.transform]\n",
    "type = \"reverse_sigmoid\"\n",
    "low = 0\n",
    "high = 4\n",
    "k = 0.5\n",
    "\n",
    "[[stage.scoring.component]]\n",
    "[stage.scoring.component.NumRotBond]\n",
    "[[stage.scoring.component.NumRotBond.endpoint]]\n",
    "name = \"Rotatable_Bonds\"\n",
    "weight = 0.2\n",
    "\n",
    "[stage.scoring.component.NumRotBond.endpoint.transform]\n",
    "type = \"reverse_sigmoid\"\n",
    "low = 0\n",
    "high = 8\n",
    "k = 0.5\n",
    "\n",
    "[[stage.scoring.component]]\n",
    "[stage.scoring.component.NumRings]\n",
    "[[stage.scoring.component.NumRings.endpoint]]\n",
    "name = \"Ring_Count\"\n",
    "weight = 0.2\n",
    "\n",
    "[stage.scoring.component.NumRings.endpoint.transform]\n",
    "type = \"reverse_sigmoid\"\n",
    "low = 2\n",
    "high = 5\n",
    "k = 0.5\n",
    "\n",
    "# ========================================\n",
    "# 第五优先级：毒性过滤（精简版）\n",
    "# ========================================\n",
    "[[stage.scoring.component]]\n",
    "[stage.scoring.component.CustomAlerts]\n",
    "[[stage.scoring.component.CustomAlerts.endpoint]]\n",
    "name = \"Toxicity_Alerts\"\n",
    "weight = 1.2\n",
    "\n",
    "[stage.scoring.component.CustomAlerts.endpoint.params]\n",
    "smarts = [\n",
    "    \"N=N\",\n",
    "    \"[N;R0]=[N;R0][#6]\",\n",
    "    \"C(=O)Cl\",\n",
    "    \"[#6]OO[#6]\",\n",
    "    \"C(=O)C(=O)\",\n",
    "    \"[Cl,Br,I][#6][Cl,Br,I]\",\n",
    "]\n",
    "\n",
    "[[stage.scoring.component]]\n",
    "[stage.scoring.component.CustomAlerts]\n",
    "[[stage.scoring.component.CustomAlerts.endpoint]]\n",
    "name = \"PAINS_Filter\"\n",
    "weight = 0.8\n",
    "\n",
    "[stage.scoring.component.CustomAlerts.endpoint.params]\n",
    "smarts = [\n",
    "    \"O=C1C=CC(=O)C=C1\",\n",
    "    \"[OH]c1ccccc1[OH]\",\n",
    "    \"c1ccc2c(c1)[nH]c1ccccc12\",\n",
    "]\n",
    "'''\n",
    "\n",
    "config_path = EXP_DIR / \"config.toml\"\n",
    "with open(config_path, 'w') as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(f\"\\n✅ 配置文件已生成: {config_path}\")\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(\"Baseline配置摘要:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  batch_size:    {BATCH_SIZE:>6}  (↓ 从512优化)\")\n",
    "print(f\"  sigma:         {SIGMA:>6}  (探索强度)\")\n",
    "print(f\"  learning_rate: {LEARNING_RATE:>6}\")\n",
    "print(f\"  bucket_size:   {BUCKET_SIZE:>6}\")\n",
    "print(f\"  min_score:     {MIN_SCORE:>6}  (↓ 允许更多探索)\")\n",
    "print(f\"  max_steps:     {MAX_STEPS:>6}\")\n",
    "print(f\"\\n  预期分子数:    ~{BATCH_SIZE * MAX_STEPS:,}\")\n",
    "print(f\"  Scoring组件:   12个 (精简版)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: TensorBoard启动指南\n",
    "print(\"=\" * 80)\n",
    "print(\"TensorBoard 实时监控设置\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "tb_logdir = EXP_DIR / \"tensorboard\"\n",
    "\n",
    "print(f\"\"\"\n",
    "┌────────────────────────────────────────────────────────────────┐\n",
    "│  在另一个终端窗口运行以下命令启动TensorBoard:                    │\n",
    "├────────────────────────────────────────────────────────────────┤\n",
    "│                                                                │\n",
    "│  cd {REINVENT_HOME}\n",
    "│  tensorboard --logdir {tb_logdir.relative_to(REINVENT_HOME)} --bind_all --port 6006\n",
    "│                                                                │\n",
    "├────────────────────────────────────────────────────────────────┤\n",
    "│  然后在浏览器访问:                                              │\n",
    "│    http://<spark-hostname>:6006                                │\n",
    "│  或者本地:                                                      │\n",
    "│    http://localhost:6006                                       │\n",
    "├────────────────────────────────────────────────────────────────┤\n",
    "│  TensorBoard将显示:                                            │\n",
    "│    • Score曲线 (total_score, DENV_Activity等)                  │\n",
    "│    • NLL曲线 (Agent, Prior)                                    │\n",
    "│    • Valid率                                                   │\n",
    "│    • 学习进度                                                  │\n",
    "└────────────────────────────────────────────────────────────────┘\n",
    "\"\"\")\n",
    "\n",
    "# 可选：自动启动TensorBoard（后台）\n",
    "start_tb = input(\"是否现在启动TensorBoard后台进程? (y/n): \").strip().lower()\n",
    "if start_tb == 'y':\n",
    "    tb_cmd = f\"nohup tensorboard --logdir {tb_logdir} --bind_all --port 6006 > {EXP_DIR}/tensorboard.log 2>&1 &\"\n",
    "    os.system(tb_cmd)\n",
    "    print(\"\\n✅ TensorBoard已在后台启动 (端口6006)\")\n",
    "    print(f\"   日志: {EXP_DIR}/tensorboard.log\")\n",
    "else:\n",
    "    print(\"\\n跳过TensorBoard启动，可稍后手动启动\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: 资源监控工具\n",
    "print(\"=\" * 80)\n",
    "print(\"资源监控工具\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def get_gpu_usage():\n",
    "    \"\"\"获取GPU使用情况\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total', '--format=csv,noheader,nounits'],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            parts = result.stdout.strip().split(', ')\n",
    "            return {\n",
    "                'gpu_util': float(parts[0]),\n",
    "                'mem_used': float(parts[1]) / 1024,  # GB\n",
    "                'mem_total': float(parts[2]) / 1024  # GB\n",
    "            }\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def get_cpu_usage():\n",
    "    \"\"\"获取CPU使用情况\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['cat', '/proc/loadavg'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            load = float(result.stdout.split()[0])\n",
    "            return load / os.cpu_count() * 100\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "# 显示当前状态\n",
    "gpu_info = get_gpu_usage()\n",
    "cpu_usage = get_cpu_usage()\n",
    "\n",
    "if gpu_info:\n",
    "    print(f\"\\nGPU状态:\")\n",
    "    print(f\"  利用率: {gpu_info['gpu_util']:.1f}%\")\n",
    "    print(f\"  内存:   {gpu_info['mem_used']:.1f} / {gpu_info['mem_total']:.1f} GB\")\n",
    "\n",
    "if cpu_usage:\n",
    "    print(f\"\\nCPU负载: {cpu_usage:.1f}%\")\n",
    "\n",
    "print(\"\\n✅ 监控工具就绪\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: 启动REINVENT4训练\n",
    "print(\"=\" * 80)\n",
    "print(\"启动REINVENT4训练 - Baseline\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "start_time = datetime.now()\n",
    "print(f\"\\n开始时间: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\n预计生成分子: ~{BATCH_SIZE * MAX_STEPS:,}\")\n",
    "print(f\"预计运行时间: 3-5 小时\\n\")\n",
    "\n",
    "# 切换到REINVENT目录\n",
    "os.chdir(REINVENT_HOME)\n",
    "print(f\"当前目录: {os.getcwd()}\\n\")\n",
    "\n",
    "# 准备命令\n",
    "config_rel_path = config_path.relative_to(REINVENT_HOME)\n",
    "log_path = EXP_DIR / \"training.log\"\n",
    "\n",
    "cmd = f\"reinvent {config_rel_path}\"\n",
    "print(f\"执行命令: {cmd}\")\n",
    "print(f\"日志文件: {log_path}\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(\"训练开始... (输出将实时显示)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# 执行训练（实时输出）\n",
    "with open(log_path, 'w') as log_file:\n",
    "    process = subprocess.Popen(\n",
    "        cmd,\n",
    "        shell=True,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1\n",
    "    )\n",
    "    \n",
    "    step_count = 0\n",
    "    for line in process.stdout:\n",
    "        log_file.write(line)\n",
    "        log_file.flush()\n",
    "        \n",
    "        # 只显示关键信息\n",
    "        if 'Score:' in line or 'INFO' in line or 'WARN' in line or 'ERROR' in line or 'CRIT' in line:\n",
    "            print(line.rstrip())\n",
    "            \n",
    "            # 统计步数\n",
    "            if 'Score:' in line and 'Step:' in line:\n",
    "                step_count += 1\n",
    "                if step_count % 100 == 0:\n",
    "                    elapsed = (datetime.now() - start_time).total_seconds() / 60\n",
    "                    rate = step_count / elapsed if elapsed > 0 else 0\n",
    "                    eta = (MAX_STEPS - step_count) / rate if rate > 0 else 0\n",
    "                    print(f\"\\n--- 进度: {step_count}/{MAX_STEPS} steps, {elapsed:.1f}分钟已过, 预计还需{eta:.1f}分钟 ---\\n\")\n",
    "    \n",
    "    process.wait()\n",
    "\n",
    "end_time = datetime.now()\n",
    "duration = (end_time - start_time).total_seconds() / 60\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "if process.returncode == 0:\n",
    "    print(f\"✅ 训练完成！\")\n",
    "else:\n",
    "    print(f\"❌ 训练失败 (返回码: {process.returncode})\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n结束时间: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"总用时: {duration:.1f} 分钟\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: 结果分析\n",
    "print(\"=\" * 80)\n",
    "print(\"结果分析\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 查找结果CSV文件\n",
    "csv_files = sorted(EXP_DIR.glob(\"results_*.csv\"))\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"\\n❌ 未找到结果CSV文件\")\n",
    "else:\n",
    "    csv_file = csv_files[0]\n",
    "    print(f\"\\n加载结果文件: {csv_file.name}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        print(f\"\\n数据维度: {df.shape}\")\n",
    "        print(f\"总生成分子数: {len(df):,}\")\n",
    "        \n",
    "        # 基本统计\n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(\"SMILES有效性统计\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        if 'SMILES_state' in df.columns:\n",
    "            valid = df[df['SMILES_state'] == 1]\n",
    "            invalid = df[df['SMILES_state'] == 0]\n",
    "            duplicates = df[df['SMILES_state'] == 2]\n",
    "            \n",
    "            print(f\"  Valid:      {len(valid):>8,} ({len(valid)/len(df)*100:>5.1f}%)\")\n",
    "            print(f\"  Invalid:    {len(invalid):>8,} ({len(invalid)/len(df)*100:>5.1f}%)\")\n",
    "            print(f\"  Duplicates: {len(duplicates):>8,} ({len(duplicates)/len(df)*100:>5.1f}%)\")\n",
    "        \n",
    "        if 'SMILES' in df.columns:\n",
    "            unique_smiles = df['SMILES'].nunique()\n",
    "            print(f\"  Unique:     {unique_smiles:>8,} ({unique_smiles/len(df)*100:>5.1f}%)\")\n",
    "        \n",
    "        # 分数统计\n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(\"Score统计\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        score_cols = ['total_score', 'DENV_Activity', 'QED', 'SA']\n",
    "        for col in score_cols:\n",
    "            if col in df.columns:\n",
    "                print(f\"  {col:20s}: {df[col].mean():>6.3f} ± {df[col].std():.3f}  (max: {df[col].max():.3f})\")\n",
    "        \n",
    "        # 高分分子统计\n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(\"高分分子统计\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        if 'total_score' in df.columns:\n",
    "            for threshold in [0.5, 0.6, 0.7, 0.8]:\n",
    "                count = len(df[df['total_score'] >= threshold])\n",
    "                print(f\"  Score ≥ {threshold}: {count:>8,}\")\n",
    "        \n",
    "        if 'DENV_Activity' in df.columns:\n",
    "            for threshold in [6.0, 7.0, 7.5, 8.0]:\n",
    "                count = len(df[df['DENV_Activity'] >= threshold])\n",
    "                print(f\"  pIC50 ≥ {threshold}: {count:>8,}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"\\n⚠️ 读取CSV失败: {e}\")\n",
    "        print(\"可能训练未正常完成，请检查日志文件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: 可视化分析\n",
    "print(\"=\" * 80)\n",
    "print(\"可视化分析\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'df' in dir() and len(df) > 0:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle(f'REINVENT4 Baseline Results - {EXP_NAME}', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Total Score分布\n",
    "    if 'total_score' in df.columns:\n",
    "        axes[0, 0].hist(df['total_score'], bins=50, edgecolor='black', alpha=0.7)\n",
    "        axes[0, 0].axvline(df['total_score'].mean(), color='red', linestyle='--', \n",
    "                          label=f'Mean: {df[\"total_score\"].mean():.3f}')\n",
    "        axes[0, 0].set_xlabel('Total Score')\n",
    "        axes[0, 0].set_ylabel('Count')\n",
    "        axes[0, 0].set_title('Total Score Distribution')\n",
    "        axes[0, 0].legend()\n",
    "    \n",
    "    # 2. DENV Activity分布\n",
    "    if 'DENV_Activity' in df.columns:\n",
    "        axes[0, 1].hist(df['DENV_Activity'], bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "        axes[0, 1].axvline(7.5, color='red', linestyle='--', label='Gold (7.5)')\n",
    "        axes[0, 1].set_xlabel('Predicted pIC50')\n",
    "        axes[0, 1].set_ylabel('Count')\n",
    "        axes[0, 1].set_title('DENV Activity Distribution')\n",
    "        axes[0, 1].legend()\n",
    "    \n",
    "    # 3. QED分布\n",
    "    if 'QED' in df.columns:\n",
    "        axes[0, 2].hist(df['QED'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "        axes[0, 2].axvline(0.5, color='red', linestyle='--', label='Threshold')\n",
    "        axes[0, 2].set_xlabel('QED')\n",
    "        axes[0, 2].set_ylabel('Count')\n",
    "        axes[0, 2].set_title('QED Distribution')\n",
    "        axes[0, 2].legend()\n",
    "    \n",
    "    # 4. SA Score分布\n",
    "    if 'SA' in df.columns:\n",
    "        axes[1, 0].hist(df['SA'], bins=50, edgecolor='black', alpha=0.7, color='purple')\n",
    "        axes[1, 0].axvline(5.0, color='red', linestyle='--', label='Threshold')\n",
    "        axes[1, 0].set_xlabel('SA Score')\n",
    "        axes[1, 0].set_ylabel('Count')\n",
    "        axes[1, 0].set_title('Synthetic Accessibility')\n",
    "        axes[1, 0].legend()\n",
    "    \n",
    "    # 5. pIC50 vs QED\n",
    "    if 'DENV_Activity' in df.columns and 'QED' in df.columns:\n",
    "        axes[1, 1].scatter(df['DENV_Activity'], df['QED'], alpha=0.1, s=1)\n",
    "        axes[1, 1].axhline(0.5, color='red', linestyle='--', alpha=0.5)\n",
    "        axes[1, 1].axvline(7.5, color='red', linestyle='--', alpha=0.5)\n",
    "        axes[1, 1].set_xlabel('Predicted pIC50')\n",
    "        axes[1, 1].set_ylabel('QED')\n",
    "        axes[1, 1].set_title('Activity vs Drug-likeness')\n",
    "    \n",
    "    # 6. 训练进度\n",
    "    if 'step' in df.columns and 'total_score' in df.columns:\n",
    "        step_stats = df.groupby('step')['total_score'].agg(['mean', 'std'])\n",
    "        axes[1, 2].plot(step_stats.index, step_stats['mean'], linewidth=2)\n",
    "        axes[1, 2].fill_between(step_stats.index, \n",
    "                                step_stats['mean'] - step_stats['std'],\n",
    "                                step_stats['mean'] + step_stats['std'], alpha=0.3)\n",
    "        axes[1, 2].set_xlabel('Training Step')\n",
    "        axes[1, 2].set_ylabel('Mean Total Score')\n",
    "        axes[1, 2].set_title('Training Progress')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plot_path = EXP_DIR / \"baseline_analysis.png\"\n",
    "    plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"\\n✅ 图表已保存: {plot_path.name}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n⚠️ 没有数据可供可视化\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: 金标准候选提取\n",
    "print(\"=\" * 80)\n",
    "print(\"金标准候选分子提取\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'df' in dir() and len(df) > 0:\n",
    "    # 金标准阈值\n",
    "    thresholds = {\n",
    "        'SMILES_state': 1,     # Valid\n",
    "        'DENV_Activity': 7.0,  # pIC50 ≥ 7.0 (IC50 < 100nM)\n",
    "        'QED': 0.5,\n",
    "        'SA': 5.5,\n",
    "        'total_score': 0.6,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n金标准阈值:\")\n",
    "    for k, v in thresholds.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    \n",
    "    # 筛选\n",
    "    mask = pd.Series([True] * len(df))\n",
    "    for col, thresh in thresholds.items():\n",
    "        if col in df.columns:\n",
    "            if col == 'SA':  # SA越低越好\n",
    "                mask &= (df[col] <= thresh)\n",
    "            else:\n",
    "                mask &= (df[col] >= thresh)\n",
    "    \n",
    "    gold_df = df[mask].copy()\n",
    "    print(f\"\\n符合条件: {len(gold_df):,}\")\n",
    "    \n",
    "    if len(gold_df) > 0 and 'SMILES' in gold_df.columns:\n",
    "        gold_df_unique = gold_df.drop_duplicates(subset=['SMILES'])\n",
    "        print(f\"去重后: {len(gold_df_unique):,}\")\n",
    "        \n",
    "        # 保存\n",
    "        gold_output = EXP_DIR / \"gold_candidates.csv\"\n",
    "        gold_df_unique.to_csv(gold_output, index=False)\n",
    "        print(f\"\\n✅ 已保存: {gold_output.name}\")\n",
    "        \n",
    "        # 显示Top 10\n",
    "        print(\"\\nTop 10 候选 (按pIC50排序):\")\n",
    "        top10 = gold_df_unique.nlargest(10, 'DENV_Activity')\n",
    "        display_cols = ['SMILES', 'DENV_Activity', 'QED', 'SA', 'total_score']\n",
    "        display_cols = [c for c in display_cols if c in top10.columns]\n",
    "        print(top10[display_cols].to_string(index=False))\n",
    "    else:\n",
    "        print(\"\\n⚠️ 未找到符合金标准的分子\")\n",
    "else:\n",
    "    print(\"\\n⚠️ 没有数据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: 实验总结\n",
    "print(\"=\" * 80)\n",
    "print(\"Baseline实验总结\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary = f\"\"\"\n",
    "实验名称: {EXP_NAME}\n",
    "完成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "配置参数:\n",
    "  batch_size:    {BATCH_SIZE}\n",
    "  sigma:         {SIGMA}\n",
    "  learning_rate: {LEARNING_RATE}\n",
    "  bucket_size:   {BUCKET_SIZE}\n",
    "  max_steps:     {MAX_STEPS}\n",
    "\n",
    "结果文件:\n",
    "  {EXP_DIR}/\n",
    "  ├── config.toml\n",
    "  ├── results_1.csv\n",
    "  ├── gold_candidates.csv\n",
    "  ├── baseline_analysis.png\n",
    "  ├── training.log\n",
    "  └── tensorboard/\n",
    "\n",
    "下一步实验建议:\n",
    "  1. High Explore: sigma=200, rate=0.00005, bucket_size=10\n",
    "  2. Fast Converge: sigma=80, rate=0.0002, bucket_size=30\n",
    "  3. 根据Baseline结果调整权重\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# 保存总结\n",
    "summary_path = EXP_DIR / \"SUMMARY.txt\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(summary)\n",
    "print(f\"\\n✅ 总结已保存: {summary_path.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinvent4",
   "language": "python",
   "name": "reinvent4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
