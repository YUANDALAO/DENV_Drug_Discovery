#!/usr/bin/env python3
"""
DENV2 NS2B-NS3 Structure Prediction and Comparison with DENV3
è‡ªåŠ¨åŒ–æµç¨‹ï¼šAlphaFoldé¢„æµ‹ â†’ ç»“æ„å åˆ â†’ æ´»æ€§ä½ç‚¹åˆ†æ â†’ å†³ç­–å»ºè®®
"""

import os
import requests
import json
from pathlib import Path
from Bio import SeqIO, Align
from Bio.PDB import PDBParser, Superimposer, PDBIO, Selection
import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple

# ============================================================================
# ç¬¬1æ­¥ï¼šè·å–DENV2å’ŒDENV3çš„åºåˆ—
# ============================================================================

class DENVSequenceFetcher:
    """ä»UniProtè·å–DENVåºåˆ—"""
    
    UNIPROT_IDS = {
        'DENV2': 'P29991',  # DENV2 NS3 protease
        'DENV3': 'P27915',  # DENV3 NS3 protease
    }
    
    @staticmethod
    def fetch_sequence(uniprot_id: str, output_file: str) -> str:
        """ä»UniProtä¸‹è½½åºåˆ—"""
        url = f"https://rest.uniprot.org/uniprotkb/{uniprot_id}.fasta"
        response = requests.get(url)
        
        if response.status_code == 200:
            with open(output_file, 'w') as f:
                f.write(response.text)
            print(f"âœ“ å·²ä¸‹è½½ {uniprot_id} åºåˆ—åˆ° {output_file}")
            
            # è§£æåºåˆ—
            record = SeqIO.read(output_file, "fasta")
            return str(record.seq)
        else:
            raise Exception(f"âœ— æ— æ³•ä¸‹è½½ {uniprot_id}: {response.status_code}")
    
    @classmethod
    def fetch_all(cls, output_dir: str = "sequences"):
        """ä¸‹è½½æ‰€æœ‰DENVåºåˆ—"""
        Path(output_dir).mkdir(exist_ok=True)
        sequences = {}
        
        for serotype, uniprot_id in cls.UNIPROT_IDS.items():
            output_file = f"{output_dir}/{serotype}_NS3.fasta"
            sequences[serotype] = cls.fetch_sequence(uniprot_id, output_file)
        
        return sequences


# ============================================================================
# ç¬¬2æ­¥ï¼šåºåˆ—æ¯”å¯¹åˆ†æ
# ============================================================================

class SequenceAligner:
    """åºåˆ—æ¯”å¯¹å’Œä¿å®ˆæ€§åˆ†æ"""
    
    # DENV NS3è›‹ç™½é…¶å‚¬åŒ–ä¸‰è”ä½“å’Œæ´»æ€§ä½ç‚¹å…³é”®æ®‹åŸºï¼ˆåŸºäºæ–‡çŒ®ï¼‰
    CATALYTIC_TRIAD = [51, 75, 135]  # His51, Asp75, Ser135
    SUBSTRATE_BINDING = [36, 37, 51, 52, 82, 84, 85, 129, 130, 132, 133, 135, 152, 155]
    
    @staticmethod
    def align_sequences(seq1: str, seq2: str, label1: str, label2: str) -> Dict:
        """å…¨å±€åºåˆ—æ¯”å¯¹"""
        aligner = Align.PairwiseAligner()
        aligner.mode = 'global'
        aligner.match_score = 2
        aligner.mismatch_score = -1
        aligner.open_gap_score = -2
        aligner.extend_gap_score = -0.5
        
        alignments = aligner.align(seq1, seq2)
        best_alignment = alignments[0]
        
        identity = sum(a == b for a, b in zip(best_alignment[0], best_alignment[1]) 
                      if a != '-' and b != '-')
        length = min(len(seq1), len(seq2))
        identity_pct = (identity / length) * 100
        
        return {
            'alignment': best_alignment,
            'identity': identity,
            'length': length,
            'identity_percentage': identity_pct,
            'label1': label1,
            'label2': label2
        }
    
    @classmethod
    def analyze_active_site(cls, seq1: str, seq2: str) -> Dict:
        """åˆ†ææ´»æ€§ä½ç‚¹æ®‹åŸºä¿å®ˆæ€§"""
        results = {
            'catalytic_triad': [],
            'binding_site': [],
            'triad_conserved': True,
            'binding_conserved_count': 0
        }
        
        # æ£€æŸ¥å‚¬åŒ–ä¸‰è”ä½“
        for pos in cls.CATALYTIC_TRIAD:
            if pos < len(seq1) and pos < len(seq2):
                res1, res2 = seq1[pos], seq2[pos]
                conserved = (res1 == res2)
                results['catalytic_triad'].append({
                    'position': pos,
                    'DENV2': res1,
                    'DENV3': res2,
                    'conserved': conserved
                })
                if not conserved:
                    results['triad_conserved'] = False
        
        # æ£€æŸ¥åº•ç‰©ç»“åˆä½ç‚¹
        for pos in cls.SUBSTRATE_BINDING:
            if pos < len(seq1) and pos < len(seq2):
                res1, res2 = seq1[pos], seq2[pos]
                conserved = (res1 == res2)
                results['binding_site'].append({
                    'position': pos,
                    'DENV2': res1,
                    'DENV3': res2,
                    'conserved': conserved
                })
                if conserved:
                    results['binding_conserved_count'] += 1
        
        total_binding = len(results['binding_site'])
        results['binding_conservation_pct'] = (
            results['binding_conserved_count'] / total_binding * 100 
            if total_binding > 0 else 0
        )
        
        return results
    
    @staticmethod
    def print_alignment_summary(align_result: Dict, active_site_result: Dict):
        """æ‰“å°æ¯”å¯¹æ‘˜è¦"""
        print("\n" + "="*70)
        print("åºåˆ—æ¯”å¯¹ç»“æœ")
        print("="*70)
        print(f"åºåˆ—åŒæºæ€§: {align_result['identity_percentage']:.1f}%")
        print(f"æ¯”å¯¹é•¿åº¦: {align_result['length']} aa")
        
        print("\nå‚¬åŒ–ä¸‰è”ä½“ä¿å®ˆæ€§:")
        for residue in active_site_result['catalytic_triad']:
            status = "âœ“" if residue['conserved'] else "âœ—"
            print(f"  {status} ä½ç½® {residue['position']}: "
                  f"DENV2={residue['DENV2']}, DENV3={residue['DENV3']}")
        
        print(f"\nåº•ç‰©ç»“åˆä½ç‚¹ä¿å®ˆæ€§: "
              f"{active_site_result['binding_conservation_pct']:.1f}% "
              f"({active_site_result['binding_conserved_count']}/{len(active_site_result['binding_site'])})")
        
        # åˆ—å‡ºéä¿å®ˆæ®‹åŸº
        non_conserved = [r for r in active_site_result['binding_site'] 
                        if not r['conserved']]
        if non_conserved:
            print("\néä¿å®ˆçš„ç»“åˆä½ç‚¹æ®‹åŸº:")
            for res in non_conserved:
                print(f"  â€¢ ä½ç½® {res['position']}: "
                      f"DENV2={res['DENV2']} â†’ DENV3={res['DENV3']}")


# ============================================================================
# ç¬¬3æ­¥ï¼šAlphaFoldé¢„æµ‹ï¼ˆè°ƒç”¨ColabFold APIæˆ–æœ¬åœ°ï¼‰
# ============================================================================

class AlphaFoldPredictor:
    """ä½¿ç”¨AlphaFoldè¿›è¡Œç»“æ„é¢„æµ‹"""
    
    @staticmethod
    def prepare_colabfold_input(sequence: str, output_file: str, job_name: str):
        """å‡†å¤‡ColabFoldè¾“å…¥æ–‡ä»¶"""
        with open(output_file, 'w') as f:
            f.write(f">{job_name}\n")
            # æ¯60ä¸ªå­—ç¬¦æ¢è¡Œ
            for i in range(0, len(sequence), 60):
                f.write(sequence[i:i+60] + "\n")
        print(f"âœ“ ColabFoldè¾“å…¥å·²ä¿å­˜: {output_file}")
        print(f"\nè¯·è®¿é—® https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/AlphaFold2.ipynb")
        print(f"ä¸Šä¼  {output_file} è¿›è¡Œé¢„æµ‹ï¼Œæˆ–ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼ˆå¦‚å·²å®‰è£…æœ¬åœ°ç‰ˆï¼‰:")
        print(f"\ncolabfold_batch {output_file} alphafold_output/ --num-models 1")
    
    @staticmethod
    def check_prediction_quality(pdb_file: str) -> Dict:
        """æ£€æŸ¥AlphaFoldé¢„æµ‹è´¨é‡ï¼ˆpLDDTè¯„åˆ†ï¼‰"""
        parser = PDBParser(QUIET=True)
        structure = parser.get_structure('protein', pdb_file)
        
        plddt_scores = []
        for model in structure:
            for chain in model:
                for residue in chain:
                    for atom in residue:
                        if atom.name == 'CA':  # pLDDTå­˜å‚¨åœ¨B-factoråˆ—
                            plddt_scores.append(atom.bfactor)
        
        return {
            'mean_plddt': np.mean(plddt_scores),
            'min_plddt': np.min(plddt_scores),
            'max_plddt': np.max(plddt_scores),
            'scores': plddt_scores
        }


# ============================================================================
# ç¬¬4æ­¥ï¼šç»“æ„å åˆä¸æ´»æ€§ä½ç‚¹RMSDè®¡ç®—
# ============================================================================

class StructureSuperimposer:
    """ç»“æ„å åˆå’ŒRMSDåˆ†æ"""
    
    @staticmethod
    def superimpose_structures(ref_pdb: str, mobile_pdb: str, 
                               output_aligned: str = None) -> Dict:
        """å åˆä¸¤ä¸ªç»“æ„å¹¶è®¡ç®—RMSD"""
        parser = PDBParser(QUIET=True)
        ref_structure = parser.get_structure('reference', ref_pdb)
        mobile_structure = parser.get_structure('mobile', mobile_pdb)
        
        ref_atoms = Selection.unfold_entities(ref_structure, 'A')
        mobile_atoms = Selection.unfold_entities(mobile_structure, 'A')
        
        # åªä½¿ç”¨CAåŸå­è¿›è¡Œå åˆ
        ref_ca = [atom for atom in ref_atoms if atom.name == 'CA']
        mobile_ca = [atom for atom in mobile_atoms if atom.name == 'CA']
        
        # ç¡®ä¿åŸå­æ•°åŒ¹é…
        min_len = min(len(ref_ca), len(mobile_ca))
        ref_ca = ref_ca[:min_len]
        mobile_ca = mobile_ca[:min_len]
        
        # æ‰§è¡Œå åˆ
        super_imposer = Superimposer()
        super_imposer.set_atoms(ref_ca, mobile_ca)
        super_imposer.apply(mobile_structure.get_atoms())
        
        # ä¿å­˜å åˆåçš„ç»“æ„
        if output_aligned:
            io = PDBIO()
            io.set_structure(mobile_structure)
            io.save(output_aligned)
            print(f"âœ“ å åˆç»“æ„å·²ä¿å­˜: {output_aligned}")
        
        return {
            'rmsd': super_imposer.rms,
            'ref_atoms': len(ref_ca),
            'mobile_atoms': len(mobile_ca)
        }
    
    @staticmethod
    def calculate_active_site_rmsd(ref_pdb: str, mobile_pdb: str, 
                                   residue_ids: List[int]) -> float:
        """è®¡ç®—æ´»æ€§ä½ç‚¹ç‰¹å®šæ®‹åŸºçš„RMSD"""
        parser = PDBParser(QUIET=True)
        ref_structure = parser.get_structure('ref', ref_pdb)
        mobile_structure = parser.get_structure('mobile', mobile_pdb)
        
        ref_atoms = []
        mobile_atoms = []
        
        for res_id in residue_ids:
            try:
                ref_res = ref_structure[0]['A'][res_id]
                mobile_res = mobile_structure[0]['A'][res_id]
                
                # ä½¿ç”¨CAåŸå­
                ref_atoms.append(ref_res['CA'])
                mobile_atoms.append(mobile_res['CA'])
            except:
                continue
        
        if len(ref_atoms) < 3:
            return None
        
        super_imposer = Superimposer()
        super_imposer.set_atoms(ref_atoms, mobile_atoms)
        
        return super_imposer.rms


# ============================================================================
# ç¬¬5æ­¥ï¼šå¯è§†åŒ–å’Œå†³ç­–å»ºè®®
# ============================================================================

class ResultVisualizer:
    """ç»“æœå¯è§†åŒ–"""
    
    @staticmethod
    def plot_plddt_scores(plddt_data: Dict, output_file: str = "plddt_plot.png"):
        """ç»˜åˆ¶pLDDTè¯„åˆ†æ›²çº¿"""
        scores = plddt_data['scores']
        
        plt.figure(figsize=(12, 4))
        plt.plot(scores, linewidth=1)
        plt.axhline(y=70, color='r', linestyle='--', label='å¯é é˜ˆå€¼ (70)')
        plt.axhline(y=90, color='g', linestyle='--', label='é«˜ç½®ä¿¡åº¦ (90)')
        plt.xlabel('æ®‹åŸºä½ç½®')
        plt.ylabel('pLDDTè¯„åˆ†')
        plt.title(f'AlphaFoldé¢„æµ‹è´¨é‡ (å¹³å‡pLDDT: {plddt_data["mean_plddt"]:.1f})')
        plt.legend()
        plt.grid(alpha=0.3)
        plt.tight_layout()
        plt.savefig(output_file, dpi=300)
        print(f"âœ“ pLDDTå›¾å·²ä¿å­˜: {output_file}")
    
    @staticmethod
    def generate_decision_report(sequence_identity: float, 
                                active_site_conservation: float,
                                catalytic_conserved: bool,
                                global_rmsd: float = None,
                                active_site_rmsd: float = None,
                                mean_plddt: float = None) -> str:
        """ç”Ÿæˆå†³ç­–å»ºè®®æŠ¥å‘Š"""
        
        report = "\n" + "="*70 + "\n"
        report += "å†³ç­–å»ºè®®æŠ¥å‘Š\n"
        report += "="*70 + "\n\n"
        
        # è¯„åˆ†ç³»ç»Ÿ
        score = 0
        reasons = []
        
        # 1. åºåˆ—åŒæºæ€§è¯„ä¼°
        if sequence_identity >= 85:
            score += 2
            reasons.append(f"âœ“ åºåˆ—åŒæºæ€§é«˜ ({sequence_identity:.1f}%)")
        elif sequence_identity >= 70:
            score += 1
            reasons.append(f"âš  åºåˆ—åŒæºæ€§ä¸­ç­‰ ({sequence_identity:.1f}%)")
        else:
            reasons.append(f"âœ— åºåˆ—åŒæºæ€§è¾ƒä½ ({sequence_identity:.1f}%)")
        
        # 2. å‚¬åŒ–ä¸‰è”ä½“ä¿å®ˆæ€§
        if catalytic_conserved:
            score += 3
            reasons.append("âœ“ å‚¬åŒ–ä¸‰è”ä½“å®Œå…¨ä¿å®ˆ")
        else:
            reasons.append("âœ— å‚¬åŒ–ä¸‰è”ä½“å­˜åœ¨çªå˜ï¼ˆä¸¥é‡é—®é¢˜ï¼‰")
        
        # 3. æ´»æ€§ä½ç‚¹ä¿å®ˆæ€§
        if active_site_conservation >= 85:
            score += 2
            reasons.append(f"âœ“ æ´»æ€§ä½ç‚¹é«˜åº¦ä¿å®ˆ ({active_site_conservation:.1f}%)")
        elif active_site_conservation >= 70:
            score += 1
            reasons.append(f"âš  æ´»æ€§ä½ç‚¹ä¸­åº¦ä¿å®ˆ ({active_site_conservation:.1f}%)")
        else:
            reasons.append(f"âœ— æ´»æ€§ä½ç‚¹ä¿å®ˆæ€§ä½ ({active_site_conservation:.1f}%)")
        
        # 4. ç»“æ„RMSDï¼ˆå¦‚æœæœ‰ï¼‰
        if global_rmsd is not None:
            if global_rmsd < 2.0:
                score += 2
                reasons.append(f"âœ“ æ•´ä½“ç»“æ„é«˜åº¦ç›¸ä¼¼ (RMSD={global_rmsd:.2f}Ã…)")
            elif global_rmsd < 3.0:
                score += 1
                reasons.append(f"âš  æ•´ä½“ç»“æ„ç›¸ä¼¼åº¦ä¸­ç­‰ (RMSD={global_rmsd:.2f}Ã…)")
            else:
                reasons.append(f"âœ— æ•´ä½“ç»“æ„å·®å¼‚è¾ƒå¤§ (RMSD={global_rmsd:.2f}Ã…)")
        
        if active_site_rmsd is not None:
            if active_site_rmsd < 1.5:
                score += 2
                reasons.append(f"âœ“ æ´»æ€§ä½ç‚¹ç»“æ„é«˜åº¦ç›¸ä¼¼ (RMSD={active_site_rmsd:.2f}Ã…)")
            elif active_site_rmsd < 2.5:
                score += 1
                reasons.append(f"âš  æ´»æ€§ä½ç‚¹ç»“æ„ç›¸ä¼¼åº¦ä¸­ç­‰ (RMSD={active_site_rmsd:.2f}Ã…)")
        
        # 5. AlphaFoldé¢„æµ‹è´¨é‡
        if mean_plddt is not None:
            if mean_plddt >= 90:
                score += 2
                reasons.append(f"âœ“ é¢„æµ‹è´¨é‡ä¼˜ç§€ (pLDDT={mean_plddt:.1f})")
            elif mean_plddt >= 70:
                score += 1
                reasons.append(f"âš  é¢„æµ‹è´¨é‡è‰¯å¥½ (pLDDT={mean_plddt:.1f})")
            else:
                reasons.append(f"âœ— é¢„æµ‹è´¨é‡ä¸ä½³ (pLDDT={mean_plddt:.1f})")
        
        # æ‰“å°è¯„ä¼°è¯¦æƒ…
        report += "è¯„ä¼°è¯¦æƒ…:\n"
        for reason in reasons:
            report += f"  {reason}\n"
        
        report += f"\næ€»è¯„åˆ†: {score}/13\n\n"
        
        # æœ€ç»ˆå»ºè®®
        report += "æ¨èæ–¹æ¡ˆ:\n"
        if score >= 9:
            report += "  â†’ ä½¿ç”¨DENV3å®éªŒç»“æ„è¿›è¡Œå¯¹æ¥\n"
            report += "  ç†ç”±: åºåˆ—å’Œç»“æ„é«˜åº¦ä¿å®ˆï¼Œå®éªŒç»“æ„æ›´å¯é \n"
            recommendation = "DENV3"
        elif score >= 6:
            report += "  â†’ åŒè½¨éªŒè¯ï¼šåŒæ—¶ä½¿ç”¨DENV2é¢„æµ‹ç»“æ„å’ŒDENV3å®éªŒç»“æ„\n"
            report += "  ç†ç”±: ä¸¤è€…å„æœ‰ä¼˜åŠ¿ï¼Œéœ€å¯¹æ¥éªŒè¯åé€‰æ‹©\n"
            recommendation = "BOTH"
        else:
            report += "  â†’ ä¼˜å…ˆä½¿ç”¨DENV2 AlphaFoldé¢„æµ‹ç»“æ„\n"
            report += "  ç†ç”±: è¡€æ¸…å‹å·®å¼‚æ˜¾è‘—ï¼Œéœ€åŒ¹é…æ´»æ€§æ•°æ®æ¥æº\n"
            recommendation = "DENV2"
        
        if not catalytic_conserved:
            report += "\n  âš ï¸ è­¦å‘Š: å‚¬åŒ–ä¸‰è”ä½“å­˜åœ¨çªå˜ï¼å»ºè®®å®éªŒéªŒè¯æŠ‘åˆ¶æœºåˆ¶å·®å¼‚\n"
        
        report += "\n" + "="*70 + "\n"
        
        return report, recommendation


# ============================================================================
# ä¸»æµç¨‹
# ============================================================================

def main():
    """ä¸»æ‰§è¡Œæµç¨‹"""
    
    print("\nğŸ§¬ DENV2 vs DENV3 ç»“æ„åˆ†ææµç¨‹å¯åŠ¨")
    print("="*70)
    
    # åˆ›å»ºå·¥ä½œç›®å½•
    Path("sequences").mkdir(exist_ok=True)
    Path("structures").mkdir(exist_ok=True)
    Path("results").mkdir(exist_ok=True)
    
    # æ­¥éª¤1: è·å–åºåˆ—
    print("\n[æ­¥éª¤1] è·å–åºåˆ—...")
    fetcher = DENVSequenceFetcher()
    sequences = fetcher.fetch_all()
    
    # æ­¥éª¤2: åºåˆ—æ¯”å¯¹
    print("\n[æ­¥éª¤2] åºåˆ—æ¯”å¯¹åˆ†æ...")
    aligner = SequenceAligner()
    align_result = aligner.align_sequences(
        sequences['DENV2'], 
        sequences['DENV3'],
        'DENV2', 'DENV3'
    )
    active_site_result = aligner.analyze_active_site(
        sequences['DENV2'], 
        sequences['DENV3']
    )
    aligner.print_alignment_summary(align_result, active_site_result)
    
    # æ­¥éª¤3: å‡†å¤‡AlphaFoldé¢„æµ‹
    print("\n[æ­¥éª¤3] å‡†å¤‡AlphaFoldé¢„æµ‹...")
    predictor = AlphaFoldPredictor()
    predictor.prepare_colabfold_input(
        sequences['DENV2'][:185],  # NS3è›‹ç™½é…¶ç»“æ„åŸŸå‰185ä¸ªæ®‹åŸº
        "sequences/DENV2_NS3_protease.fasta",
        "DENV2_NS3_protease"
    )
    
    print("\nâ¸ï¸  æµç¨‹æš‚åœï¼šç­‰å¾…AlphaFoldé¢„æµ‹å®Œæˆ")
    print("è¯·å®Œæˆä»¥ä¸‹æ“ä½œåç»§ç»­:")
    print("  1. ä½¿ç”¨ä¸Šè¿°é“¾æ¥æˆ–å‘½ä»¤è¿è¡ŒAlphaFoldé¢„æµ‹")
    print("  2. å°†é¢„æµ‹çš„PDBæ–‡ä»¶ä¿å­˜ä¸º 'structures/DENV2_predicted.pdb'")
    print("  3. å°†DENV3å®éªŒç»“æ„ä¿å­˜ä¸º 'structures/DENV3_experimental.pdb'")
    print("  4. è¿è¡Œ: python this_script.py --continue")
    
    # ä¿å­˜ä¸­é—´ç»“æœ
    results = {
        'sequence_identity': align_result['identity_percentage'],
        'active_site_conservation': active_site_result['binding_conservation_pct'],
        'catalytic_conserved': active_site_result['triad_conserved']
    }
    
    with open('results/sequence_analysis.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print("\nâœ“ åºåˆ—åˆ†æç»“æœå·²ä¿å­˜åˆ° results/sequence_analysis.json")


def continue_analysis():
    """ç»§ç»­åˆ†æï¼ˆåœ¨è·å¾—ç»“æ„åï¼‰"""
    
    print("\nğŸ”¬ ç»§ç»­ç»“æ„æ¯”å¯¹åˆ†æ...")
    
    # åŠ è½½åºåˆ—åˆ†æç»“æœ
    with open('results/sequence_analysis.json', 'r') as f:
        seq_results = json.load(f)
    
    denv2_pdb = 'structures/DENV2_predicted.pdb'
    denv3_pdb = 'structures/DENV3_experimental.pdb'
    
    if not os.path.exists(denv2_pdb) or not os.path.exists(denv3_pdb):
        print("âœ— é”™è¯¯: æœªæ‰¾åˆ°ç»“æ„æ–‡ä»¶ï¼Œè¯·ç¡®ä¿å·²æ”¾ç½®åˆ°structures/ç›®å½•")
        return
    
    # æ­¥éª¤4: æ£€æŸ¥é¢„æµ‹è´¨é‡
    print("\n[æ­¥éª¤4] æ£€æŸ¥AlphaFoldé¢„æµ‹è´¨é‡...")
    predictor = AlphaFoldPredictor()
    plddt_data = predictor.check_prediction_quality(denv2_pdb)
    print(f"å¹³å‡pLDDT: {plddt_data['mean_plddt']:.1f}")
    print(f"æœ€ä½pLDDT: {plddt_data['min_plddt']:.1f}")
    print(f"æœ€é«˜pLDDT: {plddt_data['max_plddt']:.1f}")
    
    visualizer = ResultVisualizer()
    visualizer.plot_plddt_scores(plddt_data, 'results/plddt_scores.png')
    
    # æ­¥éª¤5: ç»“æ„å åˆ
    print("\n[æ­¥éª¤5] ç»“æ„å åˆåˆ†æ...")
    superimposer = StructureSuperimposer()
    
    superimpose_result = superimposer.superimpose_structures(
        denv3_pdb, denv2_pdb, 
        'results/DENV2_aligned_to_DENV3.pdb'
    )
    print(f"æ•´ä½“RMSD: {superimpose_result['rmsd']:.2f} Ã…")
    
    # è®¡ç®—æ´»æ€§ä½ç‚¹RMSD
    active_site_rmsd = superimposer.calculate_active_site_rmsd(
        denv3_pdb, denv2_pdb,
        SequenceAligner.SUBSTRATE_BINDING
    )
    if active_site_rmsd:
        print(f"æ´»æ€§ä½ç‚¹RMSD: {active_site_rmsd:.2f} Ã…")
    
    # æ­¥éª¤6: ç”Ÿæˆå†³ç­–æŠ¥å‘Š
    print("\n[æ­¥éª¤6] ç”Ÿæˆå†³ç­–å»ºè®®...")
    report, recommendation = visualizer.generate_decision_report(
        sequence_identity=seq_results['sequence_identity'],
        active_site_conservation=seq_results['active_site_conservation'],
        catalytic_conserved=seq_results['catalytic_conserved'],
        global_rmsd=superimpose_result['rmsd'],
        active_site_rmsd=active_site_rmsd,
        mean_plddt=plddt_data['mean_plddt']
    )
    
    print(report)
    
    # ä¿å­˜å®Œæ•´æŠ¥å‘Š
    with open('results/decision_report.txt', 'w') as f:
        f.write(report)
    
    final_results = {
        **seq_results,
        'global_rmsd': superimpose_result['rmsd'],
        'active_site_rmsd': active_site_rmsd,
        'mean_plddt': plddt_data['mean_plddt'],
        'recommendation': recommendation
    }
    
    with open('results/final_analysis.json', 'w') as f:
        json.dump(final_results, f, indent=2)
    
    print("âœ“ å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜åˆ° results/decision_report.txt")
    print("âœ“ åˆ†ææ•°æ®å·²ä¿å­˜åˆ° results/final_analysis.json")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == '--continue':
        continue_analysis()
    else:
        main()