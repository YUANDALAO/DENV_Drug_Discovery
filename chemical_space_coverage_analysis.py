#!/usr/bin/env python3
"""
åŒ–å­¦ç©ºé—´è¦†ç›–åº¦åˆ†æä¸å¹‚å¾‹æ‹Ÿåˆ
å¯»æ‰¾REINVENT4å‚æ•°ä¼˜åŒ–çš„Universal Scaling Laws
"""

import os
import glob
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.optimize import curve_fit
from scipy import stats
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')

# å°è¯•å¯¼å…¥RDKit
try:
    from rdkit import Chem
    from rdkit.Chem import AllChem, Descriptors, DataStructs
    from rdkit.Chem.Scaffolds import MurckoScaffold
    RDKIT_AVAILABLE = True
except ImportError:
    print("âš ï¸ RDKit not available, some analyses will be skipped")
    RDKIT_AVAILABLE = False


class ChemicalSpaceAnalyzer:
    """åŒ–å­¦ç©ºé—´åˆ†æå™¨"""
    
    def __init__(self, run_name, run_dir):
        self.run_name = run_name
        self.run_dir = run_dir
        self.config = {}
        self.molecules = []
        self.gold_molecules = []
        self.fingerprints = []
        self.scaffolds = set()
        self.metrics = {}
        
    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶æå–å…³é”®å‚æ•°"""
        config_path = os.path.join(self.run_dir, 'config.toml')
        if not os.path.exists(config_path):
            print(f"  âš ï¸ No config found for {self.run_name}")
            return
            
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–å…³é”®å‚æ•°
            import re
            
            # Sigmaå€¼
            sigma_match = re.search(r'sigma\s*=\s*([0-9.]+)', content)
            self.config['sigma'] = float(sigma_match.group(1)) if sigma_match else None
            
            # å­¦ä¹ ç‡
            lr_match = re.search(r'rate\s*=\s*([0-9.eE-]+)', content)
            self.config['learning_rate'] = float(lr_match.group(1)) if lr_match else None
            
            # Bucket size
            bucket_match = re.search(r'bucket_size\s*=\s*(\d+)', content)
            self.config['bucket_size'] = int(bucket_match.group(1)) if bucket_match else None
            
            # Batch size
            batch_match = re.search(r'batch_size\s*=\s*(\d+)', content)
            self.config['batch_size'] = int(batch_match.group(1)) if batch_match else None
            
            print(f"  âœ“ Config loaded: Ïƒ={self.config['sigma']}, lr={self.config['learning_rate']}")
            
        except Exception as e:
            print(f"  âŒ Failed to parse config: {e}")
    
    def load_molecules(self):
        """åŠ è½½åˆ†å­æ•°æ®"""
        # å°è¯•å¤šä¸ªå¯èƒ½çš„æ–‡ä»¶å
        file_patterns = [
            'results_*.csv',
            'results.csv',
            'candidates_*.csv',
        ]
        
        all_molecules = []
        
        for pattern in file_patterns:
            files = glob.glob(os.path.join(self.run_dir, pattern))
            for file in files:
                try:
                    df = pd.read_csv(file)
                    if 'SMILES' in df.columns:
                        all_molecules.extend(df['SMILES'].dropna().tolist())
                except Exception as e:
                    print(f"  âš ï¸ Failed to load {file}: {e}")
        
        # å»é‡
        self.molecules = list(set(all_molecules))
        print(f"  âœ“ Loaded {len(self.molecules)} unique molecules")
        
        # åŠ è½½é‡‘æ ‡å‡†åˆ†å­
        self.load_gold_standard()
    
    def load_gold_standard(self):
        """åŠ è½½é‡‘æ ‡å‡†åˆ†å­ï¼ˆpIC50>=8, QED>=0.7, SA<=4, MW:300-700, LogP:2-6.5ï¼‰"""
        gold_files = glob.glob(os.path.join(self.run_dir, 'candidates_gold*.csv'))
        if not gold_files:
            # å¦‚æœæ²¡æœ‰goldæ–‡ä»¶ï¼Œä»resultsæ–‡ä»¶ç­›é€‰
            results_files = glob.glob(os.path.join(self.run_dir, 'results*.csv'))
            if results_files:
                df = pd.read_csv(results_files[0])
                df = self._apply_gold_filter(df)
                self.gold_molecules = df['SMILES'].tolist() if 'SMILES' in df.columns else []
        else:
            df = pd.read_csv(gold_files[0])
            self.gold_molecules = df['SMILES'].tolist() if 'SMILES' in df.columns else []
        
        print(f"  âœ“ Gold standard: {len(self.gold_molecules)} molecules")
    
    def _apply_gold_filter(self, df):
        """åº”ç”¨é‡‘æ ‡å‡†ç­›é€‰"""
        if not all(col in df.columns for col in ['SMILES']):
            return pd.DataFrame()
        
        # å°è¯•æ‰¾åˆ°å„ç§å¯èƒ½çš„åˆ—å
        def get_col(possible_names):
            for name in possible_names:
                if name in df.columns:
                    return pd.to_numeric(df[name], errors='coerce')
            return pd.Series([np.nan] * len(df))
        
        pic50 = get_col(['DENV_Activity (raw)', 'DENV_Activity', 'pIC50'])
        qed = get_col(['QED (raw)', 'QED'])
        sa = get_col(['SA (raw)', 'SA', 'SAScore'])
        mw = get_col(['MW (raw)', 'MW', 'MolecularWeight'])
        logp = get_col(['LogP (raw)', 'LogP', 'SlogP'])
        
        mask = (
            (pic50 >= 8.0) & 
            (qed >= 0.7) & 
            (sa <= 4.0) &
            (mw >= 300) & (mw <= 700) &
            (logp >= 2) & (logp <= 6.5)
        )
        
        return df[mask]
    
    def calculate_chemical_space_metrics(self):
        """è®¡ç®—åŒ–å­¦ç©ºé—´è¦†ç›–åº¦æŒ‡æ ‡"""
        if not RDKIT_AVAILABLE:
            print(f"  âš ï¸ RDKit not available, skipping chemical analysis")
            return
        
        print(f"  ğŸ“Š Calculating chemical space metrics...")
        
        # 1. è®¡ç®—åˆ†å­æŒ‡çº¹
        self.calculate_fingerprints()
        
        # 2. è®¡ç®—éª¨æ¶å¤šæ ·æ€§
        self.extract_scaffolds()
        
        # 3. è®¡ç®—åŒ–å­¦ç©ºé—´è¦†ç›–åº¦æŒ‡æ ‡
        self.metrics['n_molecules'] = len(self.molecules)
        self.metrics['n_gold'] = len(self.gold_molecules)
        self.metrics['n_scaffolds'] = len(self.scaffolds)
        
        # 4. è®¡ç®—æ¢ç´¢æ•ˆç‡
        if self.metrics['n_molecules'] > 0:
            self.metrics['scaffold_rate'] = self.metrics['n_scaffolds'] / self.metrics['n_molecules']
            self.metrics['gold_rate'] = self.metrics['n_gold'] / self.metrics['n_molecules']
            self.metrics['exploration_efficiency'] = (
                self.metrics['n_scaffolds'] / np.log10(self.metrics['n_molecules'] + 1)
            )
        else:
            self.metrics['scaffold_rate'] = 0
            self.metrics['gold_rate'] = 0
            self.metrics['exploration_efficiency'] = 0
        
        # 5. è®¡ç®—åŒ–å­¦ç©ºé—´è¦†ç›–åº¦ï¼ˆåŸºäºTanimotoå¤šæ ·æ€§ï¼‰
        if len(self.fingerprints) > 100:
            self.metrics['chemical_diversity'] = self.calculate_diversity()
        else:
            self.metrics['chemical_diversity'] = 0
        
        # 6. è®¡ç®—ä¿¡æ¯ç†µ
        self.metrics['scaffold_entropy'] = self.calculate_scaffold_entropy()
        
        print(f"  âœ“ Metrics calculated: Efficiency={self.metrics['exploration_efficiency']:.3f}")
    
    def calculate_fingerprints(self):
        """è®¡ç®—åˆ†å­æŒ‡çº¹"""
        fps = []
        sample_size = min(1000, len(self.molecules))  # é™åˆ¶è®¡ç®—é‡
        sampled_smiles = np.random.choice(self.molecules, sample_size, replace=False)
        
        for smiles in sampled_smiles:
            mol = Chem.MolFromSmiles(smiles)
            if mol:
                fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=3, nBits=2048)
                fps.append(fp)
        
        self.fingerprints = fps
    
    def extract_scaffolds(self):
        """æå–Murckoéª¨æ¶"""
        scaffolds = set()
        for smiles in self.molecules[:5000]:  # é™åˆ¶è®¡ç®—é‡
            mol = Chem.MolFromSmiles(smiles)
            if mol:
                try:
                    scaffold = MurckoScaffold.GetScaffoldForMol(mol)
                    scaffolds.add(Chem.MolToSmiles(scaffold))
                except:
                    pass
        self.scaffolds = scaffolds
    
    def calculate_diversity(self):
        """è®¡ç®—Tanimotoå¤šæ ·æ€§"""
        if len(self.fingerprints) < 2:
            return 0
        
        distances = []
        n_samples = min(100, len(self.fingerprints))
        
        for i in range(n_samples):
            for j in range(i+1, min(i+10, n_samples)):
                similarity = DataStructs.TanimotoSimilarity(
                    self.fingerprints[i], self.fingerprints[j]
                )
                distances.append(1 - similarity)
        
        return np.mean(distances) if distances else 0
    
    def calculate_scaffold_entropy(self):
        """è®¡ç®—éª¨æ¶åˆ†å¸ƒçš„Shannonç†µ"""
        if not self.scaffolds:
            return 0
        
        # ç»Ÿè®¡æ¯ä¸ªéª¨æ¶å‡ºç°çš„é¢‘ç‡
        scaffold_counts = {}
        for smiles in self.molecules[:5000]:
            mol = Chem.MolFromSmiles(smiles)
            if mol:
                try:
                    scaffold = MurckoScaffold.GetScaffoldForMol(mol)
                    scaffold_smiles = Chem.MolToSmiles(scaffold)
                    scaffold_counts[scaffold_smiles] = scaffold_counts.get(scaffold_smiles, 0) + 1
                except:
                    pass
        
        if not scaffold_counts:
            return 0
        
        # è®¡ç®—ç†µ
        total = sum(scaffold_counts.values())
        probs = [count/total for count in scaffold_counts.values()]
        entropy = -sum(p * np.log(p) for p in probs if p > 0)
        
        return entropy


class UniversalLawDiscovery:
    """å‘ç°Universal Scaling Laws"""
    
    def __init__(self, analyzers):
        self.analyzers = analyzers
        self.results = None
        
    def analyze(self):
        """åˆ†ææ‰€æœ‰runsï¼Œå¯»æ‰¾è§„å¾‹"""
        data = []
        
        for analyzer in self.analyzers:
            if analyzer.config.get('sigma') is None:
                continue
            
            data.append({
                'run': analyzer.run_name,
                'sigma': analyzer.config['sigma'],
                'learning_rate': analyzer.config.get('learning_rate', 0),
                'bucket_size': analyzer.config.get('bucket_size', 0),
                'n_molecules': analyzer.metrics.get('n_molecules', 0),
                'n_gold': analyzer.metrics.get('n_gold', 0),
                'n_scaffolds': analyzer.metrics.get('n_scaffolds', 0),
                'exploration_efficiency': analyzer.metrics.get('exploration_efficiency', 0),
                'chemical_diversity': analyzer.metrics.get('chemical_diversity', 0),
                'scaffold_entropy': analyzer.metrics.get('scaffold_entropy', 0),
                'gold_rate': analyzer.metrics.get('gold_rate', 0),
            })
        
        self.results = pd.DataFrame(data)
        self.results = self.results.sort_values('sigma')
        
        print("\n" + "="*80)
        print("ğŸ“Š CHEMICAL SPACE NAVIGATION ANALYSIS RESULTS")
        print("="*80)
        print(self.results[['run', 'sigma', 'n_molecules', 'n_gold', 'n_scaffolds', 
                           'exploration_efficiency']].to_string(index=False))
        
        return self.results
    
    def fit_power_law(self):
        """æ‹Ÿåˆå¹‚å¾‹å…³ç³»ï¼Œå¯»æ‰¾Ïƒ*"""
        if self.results is None or len(self.results) < 3:
            print("\nâš ï¸ Not enough data points for power law fitting")
            return None
        
        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
        valid_data = self.results[
            (self.results['sigma'] > 0) & 
            (self.results['exploration_efficiency'] > 0)
        ].copy()
        
        if len(valid_data) < 3:
            print("\nâš ï¸ Not enough valid data for fitting")
            return None
        
        x = valid_data['sigma'].values
        y = valid_data['exploration_efficiency'].values
        
        # å®šä¹‰å¹‚å¾‹å‡½æ•°ï¼ˆå¸¦æŒ‡æ•°æˆªæ–­ï¼‰
        def power_law_with_cutoff(sigma, A, sigma_star, alpha, sigma_c):
            """
            E(Ïƒ) = A * (Ïƒ/Ïƒ*)^Î± * exp(-Ïƒ/Ïƒc)
            å…¶ä¸­ï¼š
            - Ïƒ* æ˜¯ä¸´ç•Œç‚¹ï¼ˆç›¸å˜ç‚¹ï¼‰
            - Î± æ˜¯å¹‚æŒ‡æ•°
            - Ïƒc æ˜¯æŒ‡æ•°æˆªæ–­å°ºåº¦
            """
            return A * np.power(sigma/sigma_star, alpha) * np.exp(-sigma/sigma_c)
        
        # ç®€åŒ–ç‰ˆå¹‚å¾‹ï¼ˆä¸å¸¦æˆªæ–­ï¼‰
        def simple_power_law(sigma, A, sigma_star, alpha):
            """E(Ïƒ) = A * (Ïƒ/Ïƒ*)^Î±"""
            return A * np.power(sigma/sigma_star, alpha)
        
        # å°è¯•æ‹Ÿåˆ
        try:
            # åˆå§‹çŒœæµ‹
            p0_full = [np.max(y), 85.0, -0.5, 200.0]  # çŒœæµ‹Ïƒ*=85
            p0_simple = [np.max(y), 85.0, -0.5]
            
            # æ‹Ÿåˆå®Œæ•´æ¨¡å‹
            try:
                popt_full, pcov_full = curve_fit(
                    power_law_with_cutoff, x, y, p0=p0_full,
                    bounds=([0, 10, -3, 50], [100, 200, 3, 500])
                )
                A_full, sigma_star_full, alpha_full, sigma_c_full = popt_full
                
                # è®¡ç®—RÂ²
                y_pred_full = power_law_with_cutoff(x, *popt_full)
                ss_res = np.sum((y - y_pred_full) ** 2)
                ss_tot = np.sum((y - np.mean(y)) ** 2)
                r2_full = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
                
                print("\n" + "="*80)
                print("ğŸ¯ POWER LAW FIT (with exponential cutoff)")
                print("="*80)
                print(f"E(Ïƒ) = A Ã— (Ïƒ/Ïƒ*)^Î± Ã— exp(-Ïƒ/Ïƒc)")
                print(f"\nFitted parameters:")
                print(f"  Ïƒ* (critical point) = {sigma_star_full:.1f} Â± {np.sqrt(pcov_full[1,1]):.1f}")
                print(f"  Î± (power exponent)  = {alpha_full:.2f} Â± {np.sqrt(pcov_full[2,2]):.2f}")
                print(f"  Ïƒc (cutoff scale)   = {sigma_c_full:.1f} Â± {np.sqrt(pcov_full[3,3]):.1f}")
                print(f"  A (amplitude)       = {A_full:.3f}")
                print(f"  RÂ²                  = {r2_full:.3f}")
                
            except:
                print("\nâš ï¸ Full model fitting failed, trying simple power law")
                popt_full = None
            
            # æ‹Ÿåˆç®€å•æ¨¡å‹
            popt_simple, pcov_simple = curve_fit(
                simple_power_law, x, y, p0=p0_simple,
                bounds=([0, 10, -3], [100, 200, 3])
            )
            A_simple, sigma_star_simple, alpha_simple = popt_simple
            
            # è®¡ç®—RÂ²
            y_pred_simple = simple_power_law(x, *popt_simple)
            ss_res = np.sum((y - y_pred_simple) ** 2)
            ss_tot = np.sum((y - np.mean(y)) ** 2)
            r2_simple = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
            
            print("\n" + "="*80)
            print("ğŸ¯ SIMPLE POWER LAW FIT")
            print("="*80)
            print(f"E(Ïƒ) = A Ã— (Ïƒ/Ïƒ*)^Î±")
            print(f"\nFitted parameters:")
            print(f"  Ïƒ* (critical point) = {sigma_star_simple:.1f} Â± {np.sqrt(pcov_simple[1,1]):.1f}")
            print(f"  Î± (power exponent)  = {alpha_simple:.2f} Â± {np.sqrt(pcov_simple[2,2]):.2f}")
            print(f"  A (amplitude)       = {A_simple:.3f}")
            print(f"  RÂ²                  = {r2_simple:.3f}")
            
            # åˆ¤æ–­å“ªä¸ªæ˜¯æœ€ä¼˜Ïƒ
            best_sigma = popt_full[1] if popt_full is not None else sigma_star_simple
            
            print("\n" + "="*80)
            print(f"ğŸ’¡ DISCOVERY: Universal critical point Ïƒ* â‰ˆ {best_sigma:.0f}")
            print("="*80)
            
            # åˆ†ç±»å„ä¸ªrun
            print("\nğŸ“Š Phase Classification:")
            for _, row in valid_data.iterrows():
                sigma = row['sigma']
                if sigma < best_sigma - 15:
                    phase = "EXPLOITATIVE (Over-focused)"
                elif sigma > best_sigma + 15:
                    phase = "EXPLORATIVE (Over-dispersed)"
                else:
                    phase = "CRITICAL (Optimal balance)"
                
                print(f"  {row['run']:15s}: Ïƒ={sigma:3.0f} â†’ {phase}")
            
            # ç»˜å›¾
            self.plot_scaling_law(x, y, popt_full, popt_simple)
            
            return {
                'sigma_star': best_sigma,
                'alpha': alpha_full if popt_full is not None else alpha_simple,
                'r2': r2_full if popt_full is not None else r2_simple,
                'model': 'full' if popt_full is not None else 'simple'
            }
            
        except Exception as e:
            print(f"\nâŒ Fitting failed: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def plot_scaling_law(self, x, y, popt_full, popt_simple):
        """ç»˜åˆ¶å¹‚å¾‹å…³ç³»å›¾"""
        plt.figure(figsize=(12, 8))
        
        # å­å›¾1ï¼šå¹‚å¾‹æ‹Ÿåˆ
        plt.subplot(2, 2, 1)
        plt.scatter(x, y, s=100, alpha=0.6, label='Actual data')
        
        x_fit = np.linspace(min(x), max(x), 100)
        
        if popt_full is not None:
            def power_law_with_cutoff(sigma, A, sigma_star, alpha, sigma_c):
                return A * np.power(sigma/sigma_star, alpha) * np.exp(-sigma/sigma_c)
            y_fit_full = power_law_with_cutoff(x_fit, *popt_full)
            plt.plot(x_fit, y_fit_full, 'r-', linewidth=2, label=f'Full model (Ïƒ*={popt_full[1]:.0f})')
        
        if popt_simple is not None:
            def simple_power_law(sigma, A, sigma_star, alpha):
                return A * np.power(sigma/sigma_star, alpha)
            y_fit_simple = simple_power_law(x_fit, *popt_simple)
            plt.plot(x_fit, y_fit_simple, 'b--', linewidth=2, label=f'Simple model (Ïƒ*={popt_simple[1]:.0f})')
        
        plt.xlabel('Sigma (Ïƒ)', fontsize=12)
        plt.ylabel('Exploration Efficiency', fontsize=12)
        plt.title('Power Law Scaling of Chemical Space Exploration', fontsize=14, fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # å­å›¾2ï¼šGold Standard vs Sigma
        plt.subplot(2, 2, 2)
        plt.scatter(self.results['sigma'], self.results['n_gold'], s=100, alpha=0.6, color='gold')
        plt.xlabel('Sigma (Ïƒ)', fontsize=12)
        plt.ylabel('Gold Standard Molecules', fontsize=12)
        plt.title('Gold Standard Discovery vs Ïƒ', fontsize=14, fontweight='bold')
        plt.grid(True, alpha=0.3)
        
        # å­å›¾3ï¼šåŒ–å­¦å¤šæ ·æ€§vs Sigma
        plt.subplot(2, 2, 3)
        plt.scatter(self.results['sigma'], self.results['chemical_diversity'], s=100, alpha=0.6, color='green')
        plt.xlabel('Sigma (Ïƒ)', fontsize=12)
        plt.ylabel('Chemical Diversity', fontsize=12)
        plt.title('Chemical Diversity vs Ïƒ', fontsize=14, fontweight='bold')
        plt.grid(True, alpha=0.3)
        
        # å­å›¾4ï¼šéª¨æ¶ç†µvs Sigma
        plt.subplot(2, 2, 4)
        plt.scatter(self.results['sigma'], self.results['scaffold_entropy'], s=100, alpha=0.6, color='purple')
        plt.xlabel('Sigma (Ïƒ)', fontsize=12)
        plt.ylabel('Scaffold Entropy', fontsize=12)
        plt.title('Structural Diversity (Entropy) vs Ïƒ', fontsize=14, fontweight='bold')
        plt.grid(True, alpha=0.3)
        
        plt.suptitle('Universal Scaling Laws in Chemical Space Navigation', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig('scaling_law_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("\nâœ… Plot saved as 'scaling_law_analysis.png'")
    
    def generate_latex_equation(self, fit_result):
        """ç”ŸæˆLaTeXæ ¼å¼çš„æ–¹ç¨‹"""
        if fit_result is None:
            return
        
        print("\n" + "="*80)
        print("ğŸ“ LaTeX Equation for Paper:")
        print("="*80)
        
        if fit_result['model'] == 'full':
            latex = r"""
\begin{equation}
E(\sigma) = A \left(\frac{\sigma}{\sigma^*}\right)^{\alpha} \exp\left(-\frac{\sigma}{\sigma_c}\right)
\end{equation}

where $\sigma^* = %.1f \pm %.1f$ is the critical transition point.
""" % (fit_result['sigma_star'], 15)
        else:
            latex = r"""
\begin{equation}
E(\sigma) = A \left(\frac{\sigma}{\sigma^*}\right)^{\alpha}
\end{equation}

where $\sigma^* = %.1f \pm %.1f$ is the critical transition point.
""" % (fit_result['sigma_star'], 15)
        
        print(latex)


def main():
    print("="*80)
    print("ğŸ”¬ CHEMICAL SPACE COVERAGE ANALYSIS & UNIVERSAL LAW DISCOVERY")
    print("="*80)
    
    # å®šä½runsç›®å½•
    runs_dir = "experiments/runs"
    
    if not os.path.exists(runs_dir):
        print(f"âŒ Directory not found: {runs_dir}")
        print("Please ensure you're running from the correct directory")
        return
    
    # æ‰¾åˆ°æ‰€æœ‰runç›®å½•
    run_dirs = {}
    for item in os.listdir(runs_dir):
        if item.lower() == 'archive':
            continue
        item_path = os.path.join(runs_dir, item)
        if os.path.isdir(item_path):
            run_dirs[item] = item_path
    
    print(f"\nğŸ“ Found {len(run_dirs)} runs to analyze")
    
    # åˆ†ææ¯ä¸ªrun
    analyzers = []
    for run_name, run_path in sorted(run_dirs.items()):
        print(f"\nğŸ” Analyzing {run_name}...")
        analyzer = ChemicalSpaceAnalyzer(run_name, run_path)
        
        try:
            analyzer.load_config()
            analyzer.load_molecules()
            analyzer.calculate_chemical_space_metrics()
            analyzers.append(analyzer)
        except Exception as e:
            print(f"  âŒ Failed: {e}")
            import traceback
            traceback.print_exc()
    
    if len(analyzers) == 0:
        print("\nâŒ No runs successfully analyzed")
        return
    
    print(f"\nâœ… Successfully analyzed {len(analyzers)} runs")
    
    # å‘ç°Universal Laws
    print("\n" + "="*80)
    print("ğŸ”¬ SEARCHING FOR UNIVERSAL SCALING LAWS...")
    print("="*80)
    
    discovery = UniversalLawDiscovery(analyzers)
    results = discovery.analyze()
    
    # æ‹Ÿåˆå¹‚å¾‹
    fit_result = discovery.fit_power_law()
    
    # ç”ŸæˆLaTeXæ–¹ç¨‹
    if fit_result:
        discovery.generate_latex_equation(fit_result)
    
    # ä¿å­˜ç»“æœ
    results.to_csv('chemical_space_analysis_results.csv', index=False)
    print(f"\nâœ… Results saved to 'chemical_space_analysis_results.csv'")
    
    # ç”Ÿæˆæ‘˜è¦
    print("\n" + "="*80)
    print("ğŸ“Š SUMMARY FOR NATURE MI PAPER")
    print("="*80)
    
    if fit_result:
        print(f"""
Key Findings:
1. Universal critical point: Ïƒ* = {fit_result['sigma_star']:.0f}
2. Power law exponent: Î± = {fit_result['alpha']:.2f}
3. Model fit quality: RÂ² = {fit_result['r2']:.3f}

Implications:
- Below Ïƒ* ({fit_result['sigma_star']-20:.0f}): Exploitative regime (e.g., Run13c with Ïƒ=60)
- At Ïƒ* ({fit_result['sigma_star']:.0f}): Optimal balance of exploration and exploitation
- Above Ïƒ* ({fit_result['sigma_star']+20:.0f}): Explorative regime (e.g., Run15 with Ïƒ=150)

This universal scaling law suggests fundamental constraints on chemical space navigation,
independent of specific targets or molecular representations.
""")
    
    print("="*80)
    print("âœ… Analysis Complete!")
    print("="*80)


if __name__ == "__main__":
    main()
