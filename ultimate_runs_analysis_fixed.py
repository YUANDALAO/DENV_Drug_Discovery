#!/usr/bin/env python3
"""
REINVENT4 ç»ˆæžåˆ†æžå·¥å…· - ä¿®å¤ç‰ˆ
- ä¿®å¤é‡‘æ ‡å‡†ç­›é€‰é€»è¾‘
- æ­£ç¡®è¯†åˆ«run15çš„æ¯’æ€§ç»„ä»¶
- è°ƒè¯•è¾“å‡ºå¸®åŠ©å®šä½é—®é¢˜
"""
import os
import glob
import pandas as pd
import numpy as np
from datetime import datetime
import re
import warnings
import base64
from io import BytesIO
from collections import Counter
warnings.filterwarnings('ignore')

class ConfigParser:
    """è§£æžTOMLé…ç½®æ–‡ä»¶"""
    
    @staticmethod
    def parse_toml(filepath):
        config = {
            'run_type': None,
            'device': None,
            'prior_file': None,
            'agent_file': None,
            'smiles_file': None,
            'batch_size': None,
            'learning_rate': None,
            'sigma': None,
            'scoring_type': None,
            'components': [],
            'component_weights': {},
            'has_toxicity': False,
            'toxicity_components': [],
        }
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
            
            config['run_type'] = ConfigParser._extract(content, r'run_type\s*=\s*"([^"]+)"')
            config['device'] = ConfigParser._extract(content, r'device\s*=\s*"([^"]+)"')
            config['prior_file'] = ConfigParser._extract(content, r'prior_file\s*=\s*"([^"]+)"')
            config['agent_file'] = ConfigParser._extract(content, r'agent_file\s*=\s*"([^"]+)"')
            config['smiles_file'] = ConfigParser._extract(content, r'smiles_file\s*=\s*"([^"]+)"')
            config['batch_size'] = ConfigParser._extract(content, r'batch_size\s*=\s*(\d+)', int)
            config['learning_rate'] = ConfigParser._extract(content, r'rate\s*=\s*([0-9.]+)', float)
            config['sigma'] = ConfigParser._extract(content, r'sigma\s*=\s*([0-9.]+)', float)
            
            scoring_match = re.search(r'\[(?:stage\.)?scoring\]\s*type\s*=\s*"([^"]+)"', content)
            if scoring_match:
                config['scoring_type'] = scoring_match.group(1)
            
            components = ConfigParser._extract_components(content)
            config['components'] = [c['name'] for c in components]
            config['component_weights'] = {c['name']: c['weight'] for c in components}
            config['component_details'] = components
            
            # æ›´ç²¾ç¡®çš„æ¯’æ€§ç»„ä»¶æ£€æµ‹
            toxicity_keywords = {
                'toxicity': ['Toxicity_Alerts', 'Toxic'],
                'pains': ['PAINS_Filter', 'PAINS'],
                'metabolic': ['Metabolic_Stability', 'Metabolism'],
                'admet': ['ADMET', 'Safety'],
                'alerts': ['CustomAlerts']  # å¦‚æžœåç§°åŒ…å«toxicity/painsç­‰
            }
            
            for comp in config['components']:
                comp_lower = comp.lower()
                for category, keywords in toxicity_keywords.items():
                    if any(kw.lower() in comp_lower for kw in keywords):
                        config['has_toxicity'] = True
                        config['toxicity_components'].append(comp)
                        break
            
        except Exception as e:
            print(f"    âš ï¸  é…ç½®è§£æžé”™è¯¯: {e}")
        
        return config
    
    @staticmethod
    def _extract(content, pattern, dtype=str):
        match = re.search(pattern, content)
        if match:
            try:
                return dtype(match.group(1))
            except:
                return match.group(1)
        return None
    
    @staticmethod
    def _extract_components(content):
        components = []
        component_pattern = r'\[\[(?:stage\.)?scoring\.component\]\]\s*\[(?:stage\.)?scoring\.component\.(\w+)\]'
        
        for match in re.finditer(component_pattern, content):
            comp_name = match.group(1)
            comp_start = match.start()
            next_comp = re.search(r'\[\[(?:stage\.)?scoring\.component\]\]', content[comp_start+10:])
            comp_end = comp_start + next_comp.start() + 10 if next_comp else len(content)
            comp_section = content[comp_start:comp_end]
            
            weight_match = re.search(r'weight\s*=\s*([0-9.]+)', comp_section)
            weight = float(weight_match.group(1)) if weight_match else 1.0
            
            name_match = re.search(r'name\s*=\s*"([^"]+)"', comp_section)
            display_name = name_match.group(1) if name_match else comp_name
            
            components.append({
                'name': comp_name,
                'display_name': display_name,
                'weight': weight
            })
        
        return components


class RunAnalyzer:
    """åˆ†æžå•ä¸ªrun"""
    
    def __init__(self, run_name, run_dir):
        self.run_name = run_name
        self.run_dir = run_dir
        self.data = {}
        self.config = {}
        self.metrics = {}
        self.gold_molecules = []
        self.scaffolds = set()
    
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        print(f"  åˆ†æž {self.run_name}...")
        
        # åŠ è½½é…ç½®
        config_path = os.path.join(self.run_dir, 'config.toml')
        if os.path.exists(config_path):
            self.config = ConfigParser.parse_toml(config_path)
            tox_info = ""
            if self.config.get('has_toxicity'):
                tox_comps = self.config.get('toxicity_components', [])
                tox_info = f" [æ¯’æ€§ç»„ä»¶: {', '.join(tox_comps)}]"
            print(f"    âœ“ é…ç½®: {len(self.config['components'])} ä¸ªç»„ä»¶{tox_info}")
        
        # æ™ºèƒ½æŸ¥æ‰¾CSVæ–‡ä»¶
        csv_mapping = {
            'results': ['results_*.csv', 'results.csv'],
            'gold': ['candidates_gold.csv', 'candidates_é‡‘æ ‡å‡†*.csv', 'promising*.csv'],
            'high': ['candidates_high.csv', 'candidates_é«˜æ ‡å‡†*.csv'],
            'good': ['candidates_good.csv', 'candidates_ä¸­æ ‡å‡†*.csv'],
        }
        
        for key, patterns in csv_mapping.items():
            for pattern in patterns:
                files = glob.glob(os.path.join(self.run_dir, pattern))
                if files:
                    try:
                        df = pd.read_csv(files[0])
                        self.data[key] = df
                        print(f"    âœ“ {key}: {len(df)} æ¡")
                        break
                    except:
                        pass
        
        self._calculate_metrics()
        self._apply_gold_standard()
        self._extract_scaffolds()
    
    def _calculate_metrics(self):
        """è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡"""
        m = {}
        
        m['n_total'] = len(self.data.get('results', []))
        m['n_gold_original'] = len(self.data.get('gold', []))
        m['n_high'] = len(self.data.get('high', []))
        m['n_good'] = len(self.data.get('good', []))
        
        df = self.data.get('gold')
        if df is None or len(df) == 0:
            df = self.data.get('results')
        
        if df is not None and len(df) > 0:
            df.columns = df.columns.str.strip()
            
            col_map = {
                'total_score': ['Score', 'total_score', 'score'],
                'qsar': ['DENV_Activity (raw)', 'DENV_Activity', 'QSAR_Score', 'qsar', 'pIC50'],
                'qed': ['QED (raw)', 'QED', 'qed'],
                'mw': ['MW', 'Molecular weight', 'molecular_weight'],
                'sa': ['SA (raw)', 'SA', 'SAScore', 'sa_score'],
                'logp': ['LogP', 'SlogP (RDKit)', 'SlogP'],
                'tpsa': ['TPSA', 'tpsa'],
            }
            
            for metric, possible_cols in col_map.items():
                for col in possible_cols:
                    if col in df.columns:
                        vals = pd.to_numeric(df[col], errors='coerce').dropna()
                        if len(vals) > 0:
                            m[f'{metric}_mean'] = vals.mean()
                            m[f'{metric}_std'] = vals.std()
                            m[f'{metric}_min'] = vals.min()
                            m[f'{metric}_max'] = vals.max()
                        break
        
        self.metrics = m
    
    def _apply_gold_standard(self):
        """åº”ç”¨æ–°çš„é‡‘æ ‡å‡†ç­›é€‰ - å¸¦è°ƒè¯•è¾“å‡º"""
        df = self.data.get('gold')
        if df is None or len(df) == 0:
            df = self.data.get('results')
        
        if df is None or len(df) == 0:
            print(f"    âš ï¸  {self.run_name}: æ²¡æœ‰æ•°æ®å¯ç­›é€‰")
            self.metrics['n_gold_strict'] = 0
            return
        
        df = df.copy()
        df.columns = df.columns.str.strip()
        
        # è°ƒè¯•ï¼šæ‰“å°å¯ç”¨åˆ—å
        print(f"    ðŸ” è°ƒè¯• - å¯ç”¨åˆ—: {list(df.columns)[:10]}...")
        
        # æå–å„ä¸ªæŒ‡æ ‡
        def get_col_value(df, possible_names, metric_name):
            for name in possible_names:
                if name in df.columns:
                    vals = pd.to_numeric(df[name], errors='coerce')
                    print(f"    âœ“ {metric_name}: ä½¿ç”¨åˆ— '{name}', èŒƒå›´ {vals.min():.2f}-{vals.max():.2f}")
                    return vals
            print(f"    âœ— {metric_name}: æœªæ‰¾åˆ°åˆ— {possible_names}")
            return pd.Series([np.nan] * len(df))
        
        pic50 = get_col_value(df, ['DENV_Activity (raw)', 'DENV_Activity', 'pIC50', 'QSAR_Score'], 'pIC50')
        qed = get_col_value(df, ['QED (raw)', 'QED', 'qed'], 'QED')
        sa = get_col_value(df, ['SA (raw)', 'SA', 'SAScore', 'sa_score'], 'SA')
        mw = get_col_value(df, ['MW', 'Molecular weight', 'molecular_weight'], 'MW')
        logp = get_col_value(df, ['LogP', 'SlogP (RDKit)', 'SlogP'], 'LogP')
        
        # åº”ç”¨é‡‘æ ‡å‡†: pIC50>8.0, QED>0.7, SA<4.0, MW 300-500, LogP 1-4
        mask_pic50 = pic50 > 8.0
        mask_qed = qed > 0.7
        mask_sa = sa < 4.0
        mask_mw = (mw >= 300) & (mw <= 500)
        mask_logp = (logp >= 1) & (logp <= 4)
        
        # è°ƒè¯•ï¼šæ‰“å°æ¯ä¸ªæ¡ä»¶çš„é€šè¿‡æ•°
        print(f"    ðŸ“Š ç­›é€‰ç»Ÿè®¡:")
        print(f"       pIC50 > 8.0:    {mask_pic50.sum():6d} / {len(df)}")
        print(f"       QED > 0.7:      {mask_qed.sum():6d} / {len(df)}")
        print(f"       SA < 4.0:       {mask_sa.sum():6d} / {len(df)}")
        print(f"       MW 300-500:     {mask_mw.sum():6d} / {len(df)}")
        print(f"       LogP 1-4:       {mask_logp.sum():6d} / {len(df)}")
        
        mask = mask_pic50 & mask_qed & mask_sa & mask_mw & mask_logp
        print(f"       âœ“ å…¨éƒ¨é€šè¿‡:    {mask.sum():6d} / {len(df)}")
        
        gold_strict = df[mask]
        self.metrics['n_gold_strict'] = len(gold_strict)
        
        # ä¿å­˜é‡‘æ ‡å‡†åˆ†å­ç”¨äºŽåŽç»­åˆ†æž
        if len(gold_strict) > 0:
            for idx, row in gold_strict.iterrows():
                self.gold_molecules.append({
                    'run': self.run_name,
                    'smiles': row.get('SMILES', ''),
                    'pic50': pic50.loc[idx] if idx in pic50.index else np.nan,
                    'qed': qed.loc[idx] if idx in qed.index else np.nan,
                    'sa': sa.loc[idx] if idx in sa.index else np.nan,
                    'mw': mw.loc[idx] if idx in mw.index else np.nan,
                    'logp': logp.loc[idx] if idx in logp.index else np.nan,
                })
    
    def _extract_scaffolds(self):
        """æå–æ ¸å¿ƒéª¨æž¶"""
        try:
            from rdkit import Chem
            from rdkit.Chem.Scaffolds import MurckoScaffold
            
            for mol_data in self.gold_molecules:
                smiles = mol_data['smiles']
                if smiles:
                    mol = Chem.MolFromSmiles(smiles)
                    if mol:
                        try:
                            scaffold = MurckoScaffold.GetScaffoldForMol(mol)
                            scaffold_smiles = Chem.MolToSmiles(scaffold)
                            self.scaffolds.add(scaffold_smiles)
                        except:
                            pass
        except ImportError:
            print("    âš ï¸  RDKitæœªå®‰è£…ï¼Œè·³è¿‡éª¨æž¶åˆ†æž")


# ... (HTMLç”Ÿæˆéƒ¨åˆ†ä¿æŒä¸å˜ï¼Œå¤ªé•¿äº†è¿™é‡Œçœç•¥)
# ç»§ç»­ä½¿ç”¨ä¹‹å‰çš„HTMLReportGeneratorç±»

def main():
    print("="*80)
    print("REINVENT4 ç»ˆæžåˆ†æžå·¥å…· - ä¿®å¤ç‰ˆ")
    print("="*80)
    
    runs_dir = "experiments/runs"
    run_dirs = {}
    
    for item in os.listdir(runs_dir):
        if item.lower() == 'archive':
            continue
        item_path = os.path.join(runs_dir, item)
        if os.path.isdir(item_path):
            run_dirs[item] = item_path
    
    print(f"\næ‰¾åˆ° {len(run_dirs)} ä¸ªruns")
    
    analyzers = []
    for run_name, run_path in sorted(run_dirs.items()):
        analyzer = RunAnalyzer(run_name, run_path)
        try:
            analyzer.load_data()
            analyzers.append(analyzer)
            print(f"  âœ“ {run_name}: {analyzer.metrics.get('n_gold_strict', 0)} ä¸ªä¸¥æ ¼é‡‘æ ‡å‡†")
        except Exception as e:
            print(f"  âŒ {run_name} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\nâœ… æˆåŠŸåˆ†æž {len(analyzers)} ä¸ªruns")
    print(f"   æ€»ä¸¥æ ¼é‡‘æ ‡å‡†: {sum(a.metrics.get('n_gold_strict', 0) for a in analyzers)}")
    
    # CSVå¯¼å‡º
    if len(analyzers) > 0:
        summary_data = []
        for a in analyzers:
            summary_data.append({
                'Run': a.run_name,
                'Original_Gold': a.metrics.get('n_gold_original', 0),
                'Strict_Gold': a.metrics.get('n_gold_strict', 0),
                'Has_Toxicity': 'Yes' if a.config.get('has_toxicity') else 'No',
                'Tox_Components': ', '.join(a.config.get('toxicity_components', [])) if a.config.get('toxicity_components') else 'â€”',
            })
        
        df = pd.DataFrame(summary_data)
        df.to_csv('gold_standard_debug.csv', index=False)
        print("\nðŸ“Š è°ƒè¯•CSV: gold_standard_debug.csv")
        print("\n" + df.to_string(index=False))
    
    print("\n" + "="*80)

if __name__ == "__main__":
    main()
