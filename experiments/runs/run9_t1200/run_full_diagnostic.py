"""
ä¸€é”®è¿è¡Œå®Œæ•´è¯Šæ–­æµç¨‹
ADåˆ†æ + ä¸ç¡®å®šæ€§è¯„ä¼° + åŒ–å­¦ç©ºé—´å¯è§†åŒ– + ç»¼åˆæŠ¥å‘Š
"""

import os
import sys
import pandas as pd
import json
from typing import List

# å¯¼å…¥å‰é¢å®šä¹‰çš„ç±»
# from ad_analysis import ApplicabilityDomainAnalyzer
# from uncertainty_evaluation import UncertaintyEvaluator
# from chemical_space_visualization import ChemicalSpaceVisualizer
# from generate_diagnostic_report import DiagnosticReportGenerator


def run_full_diagnostic(
    training_smiles_file: str,
    generated_smiles_file: str,
    qsar_model_paths: List[str],
    output_dir: str = "diagnostic_results",
    project_name: str = "REINVENT4 Run"
):
    """
    è¿è¡Œå®Œæ•´çš„è¯Šæ–­æµç¨‹
    
    Args:
        training_smiles_file: è®­ç»ƒé›†SMILESæ–‡ä»¶ (CSV, åŒ…å«'SMILES'åˆ—)
        generated_smiles_file: ç”Ÿæˆåˆ†å­æ–‡ä»¶ (CSV, åŒ…å«'SMILES'åˆ—)
        qsar_model_paths: QSARæ¨¡å‹æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        project_name: é¡¹ç›®åç§°
    """
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    print("="*80)
    print(f"{project_name} - å®Œæ•´è¯Šæ–­æµç¨‹")
    print("="*80)
    print()
    
    # ========================================================================
    # Step 1: è¯»å–æ•°æ®
    # ========================================================================
    print("=" * 80)
    print("Step 1/5: è¯»å–æ•°æ®")
    print("=" * 80)
    
    try:
        train_df = pd.read_csv(training_smiles_file)
        training_smiles = train_df['SMILES'].tolist()
        print(f"âœ“ è®­ç»ƒé›†: {len(training_smiles)} ä¸ªåˆ†å­")
        
        gen_df = pd.read_csv(generated_smiles_file)
        generated_smiles = gen_df['SMILES'].tolist()
        print(f"âœ“ ç”Ÿæˆé›†: {len(generated_smiles)} ä¸ªåˆ†å­")
        
    except Exception as e:
        print(f"âœ— è¯»å–æ•°æ®å¤±è´¥: {e}")
        sys.exit(1)
    
    print()
    
    # ========================================================================
    # Step 2: ADåˆ†æ
    # ========================================================================
    print("=" * 80)
    print("Step 2/5: é€‚ç”¨åŸŸ(AD)åˆ†æ")
    print("=" * 80)
    
    try:
        from ad_analysis import ApplicabilityDomainAnalyzer
        
        ad_analyzer = ApplicabilityDomainAnalyzer(
            training_smiles=training_smiles,
            radius=2,
            n_bits=2048
        )
        
        ad_results = ad_analyzer.calculate_ad_distance(generated_smiles)
        
        # ä¿å­˜ç»“æœ
        ad_path = os.path.join(output_dir, "ad_analysis_results.csv")
        ad_results.to_csv(ad_path, index=False)
        print(f"âœ“ ADåˆ†æå®Œæˆï¼Œç»“æœä¿å­˜è‡³: {ad_path}")
        
        # å¯è§†åŒ–
        plot_path = os.path.join(output_dir, "ad_distribution.png")
        ad_analyzer.plot_ad_distribution(ad_results, save_path=plot_path)
        
        # æ ‡è®°é«˜é£é™©
        high_risk = ad_analyzer.flag_high_risk_molecules(ad_results, threshold=0.4)
        high_risk_path = os.path.join(output_dir, "ad_high_risk_molecules.csv")
        high_risk.to_csv(high_risk_path, index=False)
        
    except Exception as e:
        print(f"âœ— ADåˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    print()
    
    # ========================================================================
    # Step 3: ä¸ç¡®å®šæ€§è¯„ä¼°
    # ========================================================================
    print("=" * 80)
    print("Step 3/5: é¢„æµ‹ä¸ç¡®å®šæ€§è¯„ä¼°")
    print("=" * 80)
    
    try:
        from uncertainty_evaluation import UncertaintyEvaluator
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        valid_models = [p for p in qsar_model_paths if os.path.exists(p)]
        if len(valid_models) == 0:
            print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½•QSARæ¨¡å‹æ–‡ä»¶")
            print("   è·³è¿‡ä¸ç¡®å®šæ€§è¯„ä¼°...")
            uncertainty_results = None
        else:
            print(f"âœ“ æ‰¾åˆ° {len(valid_models)} ä¸ªæ¨¡å‹æ–‡ä»¶")
            
            evaluator = UncertaintyEvaluator(model_paths=valid_models)
            
            uncertainty_results = evaluator.predict_with_uncertainty(generated_smiles)
            
            # ä¿å­˜ç»“æœ
            unc_path = os.path.join(output_dir, "uncertainty_analysis.csv")
            uncertainty_results.to_csv(unc_path, index=False)
            print(f"âœ“ ä¸ç¡®å®šæ€§åˆ†æå®Œæˆï¼Œç»“æœä¿å­˜è‡³: {unc_path}")
            
            # å¯è§†åŒ–
            plot_path = os.path.join(output_dir, "uncertainty_distribution.png")
            evaluator.plot_uncertainty_analysis(uncertainty_results, save_path=plot_path)
            
            # è¯†åˆ«é«˜ä¸ç¡®å®šæ€§åˆ†å­
            uncertain = evaluator.identify_uncertain_predictions(uncertainty_results, threshold=1.0)
            uncertain_path = os.path.join(output_dir, "high_uncertainty_molecules.csv")
            uncertain.to_csv(uncertain_path, index=False)
            
            # æ½œåœ¨é—ç 
            gems = evaluator.flag_potential_gems(uncertainty_results, 
                                                 min_predicted=7.0,
                                                 min_uncertainty=0.5)
            gems_path = os.path.join(output_dir, "potential_gems.csv")
            gems.to_csv(gems_path, index=False)
        
    except Exception as e:
        print(f"âœ— ä¸ç¡®å®šæ€§è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        uncertainty_results = None
    
    print()
    
    # ========================================================================
    # Step 4: åŒ–å­¦ç©ºé—´å¯è§†åŒ–
    # ========================================================================
    print("=" * 80)
    print("Step 4/5: åŒ–å­¦ç©ºé—´å¯è§†åŒ–")
    print("=" * 80)
    
    try:
        from chemical_space_visualization import ChemicalSpaceVisualizer
        
        # éšæœºé‡‡æ ·(å¦‚æœæ•°æ®å¤ªå¤§)
        max_samples = 5000
        if len(training_smiles) > max_samples:
            import random
            train_sample = random.sample(training_smiles, max_samples)
            print(f"âš ï¸  è®­ç»ƒé›†è¿‡å¤§ï¼Œéšæœºé‡‡æ · {max_samples} ä¸ªåˆ†å­")
        else:
            train_sample = training_smiles
        
        if len(generated_smiles) > max_samples:
            import random
            gen_sample = random.sample(generated_smiles, max_samples)
            print(f"âš ï¸  ç”Ÿæˆé›†è¿‡å¤§ï¼Œéšæœºé‡‡æ · {max_samples} ä¸ªåˆ†å­")
        else:
            gen_sample = generated_smiles
        
        # t-SNEé™ç»´
        visualizer = ChemicalSpaceVisualizer(method='tsne')
        coords_df, reducer = visualizer.fit_transform(
            training_smiles=train_sample,
            generated_smiles=gen_sample,
            perplexity=30
        )
        
        # ä¿å­˜åæ ‡
        coords_path = os.path.join(output_dir, "chemical_space_coords.csv")
        coords_df.to_csv(coords_path, index=False)
        print(f"âœ“ åŒ–å­¦ç©ºé—´åæ ‡ä¿å­˜è‡³: {coords_path}")
        
        # å¯è§†åŒ–
        plot_path = os.path.join(output_dir, "chemical_space_visualization.png")
        
        # å¦‚æœæœ‰ADå’Œä¸ç¡®å®šæ€§ç»“æœï¼Œåˆå¹¶å¯è§†åŒ–
        if uncertainty_results is not None:
            # åªä¿ç•™é‡‡æ ·çš„åˆ†å­
            ad_sample = ad_results[ad_results['SMILES'].isin(gen_sample)]
            unc_sample = uncertainty_results[uncertainty_results['SMILES'].isin(gen_sample)]
        else:
            ad_sample = ad_results[ad_results['SMILES'].isin(gen_sample)]
            unc_sample = None
        
        visualizer.plot_chemical_space(
            df=coords_df,
            ad_results=ad_sample,
            uncertainty_results=unc_sample,
            save_path=plot_path
        )
        
        # è®¡ç®—è¦†ç›–æŒ‡æ ‡
        coverage_metrics = visualizer.calculate_coverage_metrics(coords_df)
        
        # ä¿å­˜æŒ‡æ ‡
        metrics_path = os.path.join(output_dir, "coverage_metrics.json")
        with open(metrics_path, 'w') as f:
            json.dump(coverage_metrics, f, indent=2)
        print(f"âœ“ è¦†ç›–æŒ‡æ ‡ä¿å­˜è‡³: {metrics_path}")
        
    except Exception as e:
        print(f"âœ— åŒ–å­¦ç©ºé—´å¯è§†åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        coverage_metrics = {
            'avg_nearest_neighbor_distance': 0,
            'coverage_ratio': 0,
            'extrapolation_ratio': 0,
            'n_training': len(training_smiles),
            'n_generated': len(generated_smiles)
        }
    
    print()
    
    # ========================================================================
    # Step 5: ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    # ========================================================================
    print("=" * 80)
    print("Step 5/5: ç”Ÿæˆç»¼åˆè¯Šæ–­æŠ¥å‘Š")
    print("=" * 80)
    
    try:
        from generate_diagnostic_report import DiagnosticReportGenerator
        
        # å¦‚æœæ²¡æœ‰ä¸ç¡®å®šæ€§ç»“æœï¼Œåˆ›å»ºè™šæ‹Ÿåˆ—
        if uncertainty_results is None:
            uncertainty_results = ad_results[['SMILES']].copy()
            uncertainty_results['Mean_pIC50'] = 0.0
            uncertainty_results['Std_pIC50'] = 0.0
            uncertainty_results['Confidence'] = 'Unknown'
            print("âš ï¸  æœªè¿›è¡Œä¸ç¡®å®šæ€§è¯„ä¼°ï¼ŒæŠ¥å‘Šå°†åªåŒ…å«ADåˆ†æ")
        
        reporter = DiagnosticReportGenerator(
            ad_results=ad_results,
            uncertainty_results=uncertainty_results,
            coverage_metrics=coverage_metrics,
            project_name=project_name
        )
        
        report_path = os.path.join(output_dir, "diagnostic_report.txt")
        reporter.save_report(output_path=report_path)
        
    except Exception as e:
        print(f"âœ— æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    print()
    
    # ========================================================================
    # å®Œæˆ
    # ========================================================================
    print("=" * 80)
    print("âœ“âœ“âœ“ è¯Šæ–­å®Œæˆï¼âœ“âœ“âœ“")
    print("=" * 80)
    print(f"\næ‰€æœ‰ç»“æœä¿å­˜åœ¨ç›®å½•: {output_dir}/\n")
    print("ä¸»è¦æ–‡ä»¶:")
    print(f"  1. {output_dir}/diagnostic_report.txt - ğŸ“„ æ–‡æœ¬è¯Šæ–­æŠ¥å‘Š")
    print(f"  2. {output_dir}/ad_distribution.png - ğŸ“Š ADåˆ†å¸ƒå›¾")
    print(f"  3. {output_dir}/uncertainty_distribution.png - ğŸ“Š ä¸ç¡®å®šæ€§åˆ†å¸ƒå›¾")
    print(f"  4. {output_dir}/chemical_space_visualization.png - ğŸ“Š åŒ–å­¦ç©ºé—´å›¾")
    print(f"  5. {output_dir}/risk_assessment.csv - ğŸ“‹ é£é™©è¯„ä¼°è¡¨")
    print(f"  6. {output_dir}/potential_gems.csv - â­ æ½œåœ¨é—ç åˆ—è¡¨")
    print(f"  7. {output_dir}/high_confidence_molecules.csv - âœ… é«˜ç½®ä¿¡åº¦å€™é€‰")
    print("=" * 80)
    print()


# ============================================================================
# å‘½ä»¤è¡Œæ¥å£
# ============================================================================

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="REINVENT4ç”Ÿæˆåˆ†å­è´¨é‡è¯Šæ–­å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python run_full_diagnostic.py \\
      --training data/training_set.csv \\
      --generated results/run9_t1200.csv \\
      --models model1.pkl model2.pkl model3.pkl \\
      --output diagnostic_results \\
      --name "REINVENT4 Run9_t1200"

è¾“å…¥æ–‡ä»¶æ ¼å¼:
  CSVæ–‡ä»¶å¿…é¡»åŒ…å«'SMILES'åˆ—
  
è¾“å‡º:
  æ‰€æœ‰ç»“æœä¿å­˜åœ¨--outputæŒ‡å®šçš„ç›®å½•ä¸­
        """
    )
    
    parser.add_argument(
        '--training', '-t',
        required=True,
        help='è®­ç»ƒé›†SMILESæ–‡ä»¶ (CSVæ ¼å¼ï¼ŒåŒ…å«SMILESåˆ—)'
    )
    
    parser.add_argument(
        '--generated', '-g',
        required=True,
        help='ç”Ÿæˆåˆ†å­SMILESæ–‡ä»¶ (CSVæ ¼å¼ï¼ŒåŒ…å«SMILESåˆ—)'
    )
    
    parser.add_argument(
        '--models', '-m',
        nargs='+',
        default=[],
        help='QSARæ¨¡å‹æ–‡ä»¶è·¯å¾„åˆ—è¡¨ (æ”¯æŒå¤šä¸ªæ¨¡å‹ç”¨äºä¸ç¡®å®šæ€§è¯„ä¼°)'
    )
    
    parser.add_argument(
        '--output', '-o',
        default='diagnostic_results',
        help='è¾“å‡ºç›®å½• (é»˜è®¤: diagnostic_results)'
    )
    
    parser.add_argument(
        '--name', '-n',
        default='REINVENT4 Run',
        help='é¡¹ç›®åç§° (é»˜è®¤: REINVENT4 Run)'
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.training):
        print(f"é”™è¯¯: è®­ç»ƒé›†æ–‡ä»¶ä¸å­˜åœ¨: {args.training}")
        sys.exit(1)
    
    if not os.path.exists(args.generated):
        print(f"é”™è¯¯: ç”Ÿæˆåˆ†å­æ–‡ä»¶ä¸å­˜åœ¨: {args.generated}")
        sys.exit(1)
    
    # è¿è¡Œè¯Šæ–­
    run_full_diagnostic(
        training_smiles_file=args.training,
        generated_smiles_file=args.generated,
        qsar_model_paths=args.models,
        output_dir=args.output,
        project_name=args.name
    )